{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ExCPJfooM6fy"
      },
      "source": [
        "## ***Project 1: PINNs for parametric problems vs Greedy (Advection-Diffusion equation)*** ###\n",
        "\n",
        "Train a PINN to solve the following parametric problem on \n",
        "${\\Omega} = (0, 1) \\times (0, 1)$\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "\\nabla \\cdot ({\\mu_1} \\nabla u) + \\boldsymbol{\\beta}\\cdot \\nabla{u}= 0 & \\text{in } \\Omega,\\\\\n",
        "{\\mu_1} \\nabla u \\cdot \\mathbf{n} = \\mu_2 & \\text{in } \\Gamma_{b},\\\\\n",
        "u = 0 & \\text{in } \\Gamma_{tl},\\\\\n",
        " \\nabla u \\cdot \\mathbf{n} = 0 & \\text{otherwise},\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where $\\mathbf{n}$ is the outer-normal to the portion of $\\partial \\Omega$ we consider. \n",
        "Specifically, $\\Gamma_b = [0, 1] \\times \\{0\\}$ and $\\Gamma_{tl} = ([0, 1] \\times \\{1\\}) \\cup (\\{0\\} \\times [0,1])$.\n",
        "\n",
        "The convection field is $\\boldsymbol{\\beta} = [y(1-y),0]^T$ and $(x,y)$ represent a spatial coordinate in $\\Omega$.\n",
        "The parametric space is $\\mathcal P = [0.1, 10] \\times [-1,1]$.\n",
        "\n",
        "\n",
        "Compare the results with standard ROM based on Greedy approach, both in terms of online  accuracy with respect to the FE solutions, speedups and offline computations compared with the training phase.\n",
        "\n",
        "**Hints!**\n",
        "\n",
        "1. Given a neural network $\\tilde {w} (\\mathbf x)$, the loss will be of the form\n",
        "  $$\n",
        "      MSE^{\\boldsymbol \\mu}  \\doteq MSE_b^{\\boldsymbol \\mu} + MSE_p^{\\boldsymbol \\mu}.\n",
        "  $$\n",
        "  where the boundary MSE is:\n",
        "  $$ \n",
        "          MSE_b^{\\boldsymbol \\mu} \\doteq \\frac{1}{N_b} \\sum_{k=1}^{N_b} | \\tilde{w}(\\mathbf x_k^b) - w(\\mathbf x_k^b)|^2,\n",
        "  $$\n",
        "  for $\\mathbf x_k^b \\in \\partial \\Omega \\times \\mathcal P$. \n",
        "\n",
        "  While the physical MSE is \n",
        "      \\begin{equation*}\n",
        "          MSE_{p}^{\\boldsymbol \\mu} \\doteq \\frac{1}{N_p}\\sum_{k=1}^{N_p}|\\mathcal R(\\tilde{w}(\\mathbf x_k^p))|^2,\n",
        "      \\end{equation*}\n",
        "\n",
        "  where $\\mathbf x_k^p \\in \\Omega \\times \\mathcal P$.\n",
        "2. Be careful in evaluating the coercivity constant for the greedy procedure.\n",
        "  For Advection-Diffusion problems the coercivity constant with respect the $H^1_0(\\Omega)$ _norm_ can be approximated by \n",
        "  $$\n",
        "  \\frac{\\mu_1}{1 + C_{\\Omega}^2},\n",
        "  $$\n",
        "  where $C_{\\Omega}$ is the Poincaré constant, i.e. the constant verifying \n",
        "  $$\\lvert \\lvert u \\rvert \\rvert_{L^2(\\Omega)} \\leq C_{\\Omega} \\lvert \\lvert \\nabla u \\rvert \\rvert_{L^2(\\Omega)}.$$ \n",
        "\n",
        "  The Poincaré constant can be approximated by the following eigenvalue problem: $ \\mathbb X_{H^1_{\\text{semi-norm}}} \\mathbf x = \\lambda \\mathbb X_{L^2_{\\text{norm}}}\\mathbf x$. \n",
        "  \n",
        "  Coding-wise, you can use `scipy` as follows on the inner product and reaction matrix to find $C_{\\Omega}$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNlEoNziWQvK"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "  \n",
        "eigs, vecs = scipy.linalg.eig(stiffness.todense(), mass.todense())\n",
        "min_eig = np.min(eigs.real)\n",
        "\n",
        "C_omega = 1 / np.sqrt(min_eig)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l-5bLJgZMYLT"
      },
      "source": [
        "## ***Project 2: PODnn for non-affine parametric problems vs POD (Stokes equations)*** ###\n",
        "\n",
        "Apply the POD-nn algorithm to the following Stokes system on the square ${\\Omega} = (0, 1) \\times (0, 1)$\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "-\\mu_1 \\nabla \\cdot (\\nabla \\mathbf{u}) + \\nabla p = \\mathbf{f}(\\mu_2) & \\text{in } \\Omega\\\\\n",
        "(\\nabla \\cdot \\mathbf{u}) = 0 & \\text{in } \\Omega\\\\\n",
        "u = 0 & \\text{in } ∂ \\Omega\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where $\\boldsymbol \\mu = (\\mu_1,\\mu_2) \\in \\mathcal P = [1, 10] \\times [1,3]$.\n",
        "Perform the training for two forcing terms $\\mathbf f = [f_1, f_2]^T$:\n",
        "\n",
        "1. $\\mathbf f$ as the forcing term of Lab 11.\n",
        "2. $f_1 = - \\mu_2^3\\sin(\\mu_2 \\pi y)$ \n",
        "   \n",
        "   $f_2 = \\mu_2^3\\cos(\\mu_2 \\pi y)$\n",
        "\n",
        "\n",
        "Compare the results with standard ROM based on POD approach, both in terms of online  accuracy with respect to the FE solutions, speedups and offline computations compared with the training phase.\n",
        "The task has to be reapeted for both the forcing terms.\n",
        "\n",
        "The experimental analysis must contain comments on **supremizer stabilization strategy** applied both to the POD and POD-nn algorithms, in comparison with the same approaches without supremizer stabilization."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
