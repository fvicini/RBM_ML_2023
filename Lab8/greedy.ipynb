{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IGuNCbv2QpF"
      },
      "source": [
        "# **Greedy algorithm**\n",
        "This lab focuses on performing a greedy algorithm on the parametric system we saw together in the previous lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOKm4Cpr0agg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/fvicini/CppToPython.git\n",
        "%cd CppToPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVlYTB8mifCl"
      },
      "outputs": [],
      "source": [
        "!git submodule init\n",
        "!git submodule update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xezfpm75i_FG"
      },
      "outputs": [],
      "source": [
        "!mkdir -p externals\n",
        "%cd externals\n",
        "!cmake -DINSTALL_VTK=OFF -DINSTALL_LAPACK=OFF ../gedim/3rd_party_libraries\n",
        "!make -j4\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LamP-IF1tLt"
      },
      "outputs": [],
      "source": [
        "!mkdir -p release\n",
        "%cd release \n",
        "!cmake -DCMAKE_PREFIX_PATH=\"/content/CppToPython/externals/Main_Install/eigen3;/content/CppToPython/externals/Main_Install/triangle;/content/CppToPython/externals/Main_Install/tetgen;/content/CppToPython/externals/Main_Install/googletest\" ../\n",
        "!make -j4 GeDiM4Py\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeaV-lky4gkR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import GeDiM4Py as gedim\n",
        "from scipy.sparse.linalg import splu\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13zM04WMQ5hJ"
      },
      "outputs": [],
      "source": [
        "lib = gedim.ImportLibrary(\"./release/GeDiM4Py.so\")\n",
        "\n",
        "config = { 'GeometricTolerance': 1.0e-8 }\n",
        "gedim.Initialize(config, lib)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubq1Ge_iQkak"
      },
      "source": [
        "## The parametric version of the heat conductivity equation\n",
        "\n",
        "Solve the following equation on square ${\\Omega} = (-1, +1) \\times (-1, +1)$\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "\\nabla \\cdot (k_{\\mu} \\nabla u) = 0 & \\text{in } \\Omega\\\\\n",
        "k_{\\mu} \\nabla u \\cdot n_1 = \\mu_2 & \\text{in } \\Gamma_{base}\\\\\n",
        "u = 0 & \\text{in } \\Gamma_{top}\\\\\n",
        "k_{\\mu} \\nabla u \\cdot n_2 = 0 & \\text{otherwise} \n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where $k_{\\mu} = \\mu_1$ if $x^2 + y^2 \\leq R^2$ and $k = 1$ otherwise. \n",
        "The parametric space is $\\mathcal P = [0.1, 10] \\times [-1,1]$.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1j98eKPtRy8IqsLMKkue2dINRy6yNS20j\"\n",
        " style=\"float:center;width:50px;height:50px;\" align=\"center\">\n",
        "\n",
        "\n",
        "The parameter $\\boldsymbol \\mu \\in \\mathcal P$ is physical and changes the features of the flow: \n",
        "\n",
        "1. $\\mu_1$ the conductivity in $\\Omega_1$;\n",
        "2. $\\mu_2$ describes the heat flux in the bottom part of the boundary.\n",
        "\n",
        "First thing: we define two subdomains $\\Omega_1$ and $\\Omega_2$, such that\n",
        "1. $\\Omega_1$ is a disk in the origin with radius $r_0=0.5$, and\n",
        "2. $\\Omega_2=\\Omega/\\ \\overline{\\Omega_1}$.\n",
        "3. $\\Gamma_{base}$ to define where we will change the heat flux.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOPeoKRlRNMo"
      },
      "outputs": [],
      "source": [
        "def Heat_R():\n",
        "\treturn 0.5\n",
        "\n",
        "\n",
        "def Omega1(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = np.ones(numPoints)\n",
        "\tfor p in range(0, numPoints):\n",
        "\t\tif (matPoints[0,p] * matPoints[0,p] + matPoints[1,p] * matPoints[1,p]) > (Heat_R() * Heat_R() + 1.0e-16):\n",
        "\t\t\tvalues[p] = 0.\n",
        "\treturn values.ctypes.data\n",
        "\n",
        "def Omega2(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = np.ones(numPoints)\n",
        "\tfor p in range(0, numPoints):\n",
        "\t\tif (matPoints[0,p] * matPoints[0,p] + matPoints[1,p] * matPoints[1,p]) <= (Heat_R() * Heat_R() + 1.0e-16):\n",
        "\t\t\tvalues[p] = 0. \n",
        "\treturn values.ctypes.data\n",
        "\n",
        "def Gamma_base(numPoints, points):\n",
        "\tvalues = np.ones(numPoints)\n",
        "\treturn values.ctypes.data\n",
        "\n",
        "##### needed for the inner product #####\n",
        "\n",
        "def Domain(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = np.ones(numPoints)\n",
        "\treturn values.ctypes.data\t"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal**: build the ROM space where many simulations for several parameters can be performed in a smaller amount of time. \n",
        "\n",
        "**Strategy**: $w(\\boldsymbol  \\mu)  \\xrightarrow[]{\\text{FOM} (\\dim = \\mathcal N)} w^{\\mathcal N}(\\boldsymbol \\mu)\n",
        "\\xrightarrow[\\lvert \\lvert {w(\\boldsymbol \\mu) - w^\\mathcal{N}(\\boldsymbol  \\mu)\\rvert \\rvert } \\rightarrow 0]{\\text{ROM } (\\dim N)} w_N(\\boldsymbol  \\mu)$.\n",
        "\n",
        "The goal can be reached by means of several techniques. \n",
        "\n",
        "Today we will focus on Greedy.\n",
        "\n",
        "Building the space $\\mathbb V_N \\subset \\mathbb V^{\\mathcal N}$ and store the $\\boldsymbol \\mu-$independent quantities is the so called _offline phase_ (possibly costly).\n",
        "\n",
        "Once the space is built, a fast _online phase_ occurs, where I can compute **many solutions in real-time**.\n",
        "\n",
        "We still use the affine decomposition property. Indeed we know that our system can be written as\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^{q_a} \\theta_i^a(\\boldsymbol \\mu)a_i(u,v) = \\sum_{j=0}^{q_f} \\theta_j^f(\\boldsymbol \\mu)f_j(v),\n",
        "$$\n",
        "\n",
        "i.e., algebraic-wise\n",
        "\n",
        "$$\n",
        "\\mathbb{A}(\\boldsymbol \\mu) = \\sum_{i=1}^{q_a} \\theta_i^a(\\boldsymbol \\mu) \\mathbb{A}_i = \\sum_{j=0}^{q_f} \\theta_j^f(\\boldsymbol \\mu)\\mathbf f_j = \\mathbf f(\\boldsymbol \\mu),\n",
        "$$\n",
        "where $\\mathbb{A}_i$ and $\\mathbf f_j$ are the assembled matrices and vectors of the system.\n",
        "\n",
        "Now, let us imagine to have already built the reduced space and have collected the basis functions $\\xi_{i} \\in \\mathbb R^{\\mathcal N}$ for $i \\in \\{1, \\dots, N \\}$ ($\\mathbb V_N = \\text{span}\\{\\xi_i\\}_{i=1}^{N} $) in a basis matrix \n",
        "$$\n",
        "\\mathbb B = [\\xi_1 \\cdots \\xi_N] \\in \\mathbb R^{\\mathcal N \\times N}.\n",
        "$$ \n",
        "\n",
        "It is clear that we can recast the problem in the low-dimensional framework we built, we can pre-and-post multiply the FOM matrices for the basis matrix we have:\n",
        "\n",
        "$$\n",
        "\\mathbb{A}_i^N = \\mathbb B^T \\mathbb{A}_i\\mathbb B \\quad \\text{ and } \\quad  \\mathbf f_j^N = \\mathbb B^T\\mathbf f_j.  \n",
        "$$"
      ],
      "metadata": {
        "id": "dO3ClVNFJl0Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9JEfUdDRH5W"
      },
      "source": [
        "**Let us code the OFFLINE PHASE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfzHSAXORH5X"
      },
      "outputs": [],
      "source": [
        "### order of the discretization ###\n",
        "order = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZXNw6gDlHZt"
      },
      "outputs": [],
      "source": [
        "%%writefile ImportMesh.csv\n",
        "InputFolderPath\n",
        "./Meshes/Mesh1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFrwWHkGRTcM"
      },
      "outputs": [],
      "source": [
        "[meshInfo, mesh] = gedim.ImportDomainMesh2D(lib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FifaSs5tRWLp"
      },
      "outputs": [],
      "source": [
        "gedim.PlotMesh(mesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFLs55ZIRjRw"
      },
      "source": [
        "### FEM space (the High Fidelity approximation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtVL7IqnRlra"
      },
      "outputs": [],
      "source": [
        "discreteSpace = { 'Order': order, 'Type': 1, 'BoundaryConditionsType': [1, 3, 3, 2] }\n",
        "[problemData, dofs, strongs] = gedim.Discretize(discreteSpace, lib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNKv663YRvMJ"
      },
      "outputs": [],
      "source": [
        "gedim.PlotDofs(mesh, dofs, strongs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-GPibkUR0yD"
      },
      "source": [
        "### Assemble linear system exploting affinity\n",
        "We define everything that is parameter independent:\n",
        "$$\\mathbb{A}_i,\\ i \\in \\{0,\\dots, q_a\\} \\quad \\mathbf{f}_j,\\ j \\in \\{0,\\dots, q_f\\}.$$\n",
        "Moreover, we define the matrix $\\mathbb{X}$ related to the scalar product of the problem at hand.\n",
        "Finally, we create the parameter dependent variable:\n",
        "$$θ^a_i(\\boldsymbol{\\mu}),\\ i \\in \\{0,\\dots, q_a\\} \\quad θ^f_j(\\boldsymbol{\\mu}),\\ j \\in \\{0,\\dots, q_f\\}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7XmYDOGR1m4"
      },
      "outputs": [],
      "source": [
        "[stiffness1, stiffnessStrong1] = gedim.AssembleStiffnessMatrix(Omega2, problemData, lib)\n",
        "[stiffness2, stiffnessStrong2] = gedim.AssembleStiffnessMatrix(Omega1, problemData, lib)\n",
        "\n",
        "weakTerm_down1 = gedim.AssembleWeakTerm(Gamma_base, 1, problemData, lib)\n",
        "\n",
        "#### inner product X\n",
        "# ||u||^2 + ||grad(u)||^2\n",
        "X = stiffness1 + stiffness2  ######## semi-norm (equivalent)\n",
        "\n",
        "### define the problem\n",
        "AQH = [stiffness1, stiffness2]\n",
        "fQH = [weakTerm_down1]\n",
        "\n",
        "def thetaA(mu):\n",
        "    return [1.0, mu[0]]\n",
        "def thetaF(mu):\n",
        "    return [mu[1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will define some useful functions to perform computations:"
      ],
      "metadata": {
        "id": "OqpcVJhuxJ_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normX(v, X):\n",
        "\treturn np.sqrt(np.transpose(v) @ X @ v)\n",
        "\n",
        "def ProjectSystem(AQH, fQH, B):\n",
        "    AQN = []\n",
        "    fQN = []\n",
        "    for AH in AQH:\n",
        "        AQN.append(np.copy(np.transpose(B) @ AH @ B))\n",
        "    for fH in fQH:\n",
        "        fQN.append(np.copy(np.transpose(B) @ fH))\n",
        "    return [AQN, fQN]\n",
        "\n",
        "def Solve_full_order(AQH, fQH, thetaA_mu, thetaF_mu):\n",
        "    A = thetaA_mu[0] * AQH[0]\n",
        "    f = thetaF_mu[0] * fQH[0]\n",
        "    for i in range(1, len(AQH)):\n",
        "        A += thetaA_mu[i] * AQH[i]\n",
        "    for i in range(1, len(fQH)):\n",
        "        f += thetaF_mu[i] * fQH[i]\n",
        "    return gedim.LUSolver(A, f, lib)\n",
        "\n",
        "def Solve_reduced_order(AQN, fQN, thetaA_mu, thetaF_mu):\n",
        "    A = thetaA_mu[0] * AQN[0]\n",
        "    f = thetaF_mu[0] * fQN[0]\n",
        "    for i in range(1, len(AQN)):\n",
        "        A += thetaA_mu[i] * AQN[i]\n",
        "    for i in range(1, len(fQN)):\n",
        "        f += thetaF_mu[i] * fQN[i]\n",
        "    return np.linalg.solve(A, f)"
      ],
      "metadata": {
        "id": "-HvwhZwDxNYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We here define the finite parametric space $\\mathcal P_{train}$, with random uniform distributed realization of $\\boldsymbol \\mu$.\n",
        "The cardinality of $\\mathcal P_{train}$ is set to $M=100$."
      ],
      "metadata": {
        "id": "9lmJ6XjuZGI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2dzS4-3dZm2"
      },
      "outputs": [],
      "source": [
        "### define the training set\n",
        "M = 100\n",
        "mu1_range = [0.1, 10.]\n",
        "mu2_range = [-1., 1.]\n",
        "P = np.array([mu1_range, mu2_range])\n",
        "\n",
        "training_set = np.random.uniform(low=P[:, 0], high=P[:, 1], size=(M, P.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### POD\n",
        "\n",
        "We recall POD algorithm. We will use it for comparisons.\n",
        "\n",
        "To build the $N-$dimesional framework we need, we define the correlation snapshot matrix $\\mathbb C \\in \\mathbb R^{M \\times M}$ and we solve the eigenvalue problem\n",
        "$\n",
        "    \\mathbb C \\omega_n = \\lambda_n \\omega_n\n",
        "$ for $ 1 \\leq n \\leq M,$ with $\\lvert \\lvert {\\omega_n}\\rvert \\rvert_{\\mathbb V} = 1$. \n",
        "Due to the definition of correlation matrix, we can order the all-positive eigenvalues as $\\lambda_1 >\\dots > \\lambda_{M}> 0$ and retain the first $N$ eigenpairs $(\\lambda_n, \\omega_n)$ for $1 \\leq n \\leq N$. \n",
        "\n",
        "We choose $M$ and $N$ looking at the eigenvalues.\n",
        "Indeed, defining as  $P_N: \\mathbb V \\rightarrow \\mathbb V_N$ the projector from $\\mathbb V$ onto $ {\\mathbb V}_N$, the following relation holds:\n",
        "\\begin{equation}\n",
        "    \\sqrt{\\frac{1}{M}\n",
        "    \\sum_{i = 1}^{M}  \\lvert \\lvert {u^{\\mathcal N}(\\boldsymbol{\\mu}_{i}) - P_N(u^{\\mathcal N}(\\boldsymbol{\\mu}_i)\\rvert \\rvert }_{\\mathbb V}^2} = \\sqrt{\n",
        "    \\sum_{i = N + 1}^{M}\\lambda_m.}\n",
        "\\end{equation}\n",
        "Namely, a fast decay of the eigenvalue magnitude guaratees a good representation of the high-fidelity solution with a few basis functions.\n",
        "\n",
        "Finally, we create the basis matrix $\\mathbb B$. \n",
        "There are many ways to build the bases.\n",
        "We propose the following one to guarantee more stability:\n",
        "$$    \n",
        "\\chi_n =  \\sum_{m = 1}^{M} (\\omega_n)_m u^{\\mathcal N}(\\boldsymbol{\\mu}_m),  \\quad \\quad 1 \\leq n \\leq N,\n",
        "$$\n",
        "and $\\displaystyle \\xi_n = \\frac{\\chi_n}{\\lvert \\lvert \\chi_n \\rvert \\rvert }_{\\mathbb V}$."
      ],
      "metadata": {
        "id": "Mr8_qs8YxErD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def POD(AQH, fQH, X, N_max, tol):\n",
        "    #### snapshot matrix creation\n",
        "    snapshot_matrix = []\n",
        "\n",
        "    for mu in training_set:\n",
        "        snapshot = Solve_full_order(AQH, fQH, thetaA(mu), thetaF(mu))\n",
        "        snapshot_matrix.append(np.copy(snapshot))\n",
        "    \n",
        "    snapshot_matrix = np.array(snapshot_matrix) \n",
        "\n",
        "    ### covariance matrix\n",
        "    C = snapshot_matrix @ X @ np.transpose(snapshot_matrix) ## metti inner product\n",
        "    L_e, VM_e = np.linalg.eig(C)\n",
        "    eigenvalues = []\n",
        "    eigenvectors = []\n",
        "\n",
        "    for i in range(len(L_e)):\n",
        "        eig_real = L_e[i].real\n",
        "        eig_complex = L_e[i].imag\n",
        "        assert np.isclose(eig_complex, 0.)\n",
        "        eigenvalues.append(eig_real)\n",
        "        eigenvectors.append(VM_e[i].real)\n",
        "\n",
        "    total_energy = sum(eigenvalues)\n",
        "    retained_energy_vector = np.cumsum(eigenvalues)\n",
        "    relative_retained_energy = retained_energy_vector/total_energy\n",
        "\n",
        "    if all(flag==False for flag in relative_retained_energy >= (1.0 - tol)):\n",
        "        N = N_max\n",
        "    else:\n",
        "        N = np.argmax(relative_retained_energy >= (1.0 - tol)) + 1\n",
        "\n",
        "    # Create the basis function matrix\n",
        "    basis_functions = []\n",
        "    for n in range(N):\n",
        "        eigenvector =  eigenvectors[n]\n",
        "        # basis = (1/np.sqrt(M))*np.transpose(snapshot_matrix)@eigenvector \n",
        "        basis = np.transpose(snapshot_matrix) @ eigenvector\n",
        "        norm = normX(basis, X)\n",
        "        # norm = np.sqrt(np.transpose(basis)@basis)\n",
        "        basis /= norm\n",
        "        basis_functions.append(np.copy(basis))\n",
        "\n",
        "    return [N, np.transpose(np.array(basis_functions))]"
      ],
      "metadata": {
        "id": "C-zNCCnaxDwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Greedy\n",
        "\n",
        "The **greedy generation** of the reduced basis space is an iterative procedure where at each iteration one new basis function is added and the overall precision of the basis set is improved. \n",
        "The \"ideal\" version of the Greedy algorithm reads as:\n",
        "\n",
        "Given a train set $\\mathcal{P}_{train}$, define $u_0 (\\mu) := 0$\n",
        "\n",
        "\\begin{align}\n",
        "\\text{for}\\ &N \\in \\{1, \\dots , N_{max}\\}:\\\\\n",
        "&\\boldsymbol{\\mu}_N = \\text{arg}\\max_{\\boldsymbol{\\mu} \\in \\mathcal{P}_{train}} ||u^{\\mathcal{N}}(\\boldsymbol{\\mu})-u_{N-1}(\\boldsymbol{\\mu})||_V\\\\\n",
        "&S_N = S_{N−1} \\cup \\boldsymbol{\\mu}_N\\\\\n",
        "&\\mathbb{B}_N = \\mathbb{B}_{N-1} \\cup \\text{span}\\{u_N(\\boldsymbol{\\mu}_N)\\}\n",
        "\\end{align}\n",
        "\n",
        "Possible issues are:\n",
        "* $M=|\\mathcal{P}_{train}|$ high fidelity solutions;\n",
        "* Suboptimality (heuristic).\n",
        "\n",
        "To overcome the first we use a sharp, inexpensive **a posteriori error bound** \n",
        "$$||u^{\\mathcal{N}}(\\boldsymbol{\\mu})-u_{N-1}(\\boldsymbol{\\mu})||_V \\leq Δ_N(\\boldsymbol{\\mu})$$\n",
        "thus the algorithm becomes:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{for}\\ &N \\in \\{1, \\dots , N_{max}\\}:\\\\\n",
        "&\\boldsymbol{\\mu}_N = \\text{arg}\\max_{\\mu \\in \\mathcal{P}_{train}} Δ_N(\\boldsymbol{\\mu})\\\\\n",
        "&S_N = S_{N−1} \\cup \\boldsymbol{\\mu}_N\\\\\n",
        "&\\mathbb{B}_N = \\mathbb{B}_{N-1} \\cup \\text{span}\\{u_N(\\boldsymbol{\\mu}_N)\\}\n",
        "\\end{align}\n",
        "\n",
        "****\n",
        "**NOTE**\n",
        "\n",
        "POD basis is orthonormal by construction, in the greedy setting the snapshots are **not** (necessarily) orthogonal.\n",
        "In order to obtain an orthonormal basis we rely on the **Gram-Schmidt\n",
        "orthonormalization**, for $n > 1$:\n",
        "$$z_n = u^{\\mathcal{N}}(\\boldsymbol{\\mu}_n)-\\sum_{i=0}^{N-1} (u^{\\mathcal{N}}, \\xi_i)_{\\mathbb{X}}\\xi_i$$"
      ],
      "metadata": {
        "id": "ikMeattIzADD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GramSchmidt(V, u, X):\n",
        "    z = u\n",
        "    if np.size(V) > 0:\n",
        "        z = u - V @ (np.transpose(V) @ (X @ u))\n",
        "    return z / normX(z, X)\n",
        "\n",
        "##### Greedy #####\n",
        "def Greedy(AQH, fQH, X, N_max, tol):\n",
        "    N = 0\n",
        "    basis_functions = []\n",
        "    B = np.empty((0,0))\n",
        "    deltaN = tol + 1.\n",
        "    training_set_list = training_set.tolist()\n",
        "    initial_muN = np.random.choice(len(training_set_list) - 1, 1)[0]\n",
        "    muN = training_set_list.pop(initial_muN)\n",
        "    invX = splu(X)\n",
        "\n",
        "    print('Perfom greedy algorithm...')\n",
        "    while len(training_set_list) > 0 and N < N_max and deltaN > tol:\n",
        "        N = N + 1\n",
        "        print('\\t', N,'/', N_max, '-', '{:.16e}'.format(np.mean(deltaN)), '/', '{:.16e}'.format(np.mean(tol)))\n",
        "        snapshot = Solve_full_order(AQH, fQH, thetaA(muN), thetaF(muN))\n",
        "        basis_function = GramSchmidt(B, snapshot, X)\n",
        "        basis_functions.append(np.copy(basis_function))\n",
        "        B = np.transpose(np.array(basis_functions))\n",
        "        BX = np.transpose(B) @ X @ B\n",
        "\n",
        "        [AQN, fQN] = ProjectSystem(AQH, fQH, B)\n",
        "        [Cq1q2, dq1q2, Eq1q2] = OfflineResidual(AQH, fQH, B, invX)\n",
        "\n",
        "        counter = 0\n",
        "        mu_selected_index = -1\n",
        "        max_deltaN = -1.\n",
        "        for mu in training_set_list:\n",
        "            solN_mu = Solve_reduced_order(AQN, fQN, thetaA(mu), thetaF(mu))\n",
        "            betaN_mu = InfSupConstant(mu)\n",
        "            deltaN_mu = ErrorEstimate(Cq1q2, dq1q2, Eq1q2, thetaA(mu), thetaF(mu), solN_mu, betaN_mu) / normX(solN_mu, BX)\n",
        "\t    \n",
        "            if deltaN_mu > max_deltaN:\n",
        "                max_deltaN = deltaN_mu\n",
        "                mu_selected_index = counter\n",
        "\n",
        "            counter = counter + 1\n",
        "\n",
        "        if mu_selected_index == -1:\n",
        "            raise Exception('ERROR, parameter not found')\n",
        "\n",
        "        muN = training_set_list.pop(mu_selected_index)\n",
        "        deltaN = max_deltaN\n",
        "\n",
        "    return [N, np.transpose(np.array(basis_functions))]"
      ],
      "metadata": {
        "id": "T6Z1YppMzWDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To compute the estimator $Δ_N(\\boldsymbol{\\mu})$ we rely on the error bound\n",
        "$$\\frac{1}{\\gamma^{\\mathcal{N}}(\\boldsymbol{\\mu})} ||r(\\boldsymbol{\\mu})||_{\\mathbb{V}'}\\leq ||e^{\\mathcal{N}}(\\boldsymbol{\\mu})|| \\leq \\frac{1}{\\beta^{\\mathcal{N}}(\\boldsymbol{\\mu})} ||r(\\boldsymbol{\\mu})||_{\\mathbb{V}'}  $$\n",
        "where $e^{\\mathcal{N}}(\\boldsymbol{\\mu}) := u^{\\mathcal{N}}(\\boldsymbol{\\mu})-u_{N}(\\boldsymbol{\\mu})$ and $r(\\boldsymbol{\\mu}) \\in \\mathbb{V}'$ is the **residual** of the high-fidelity problem computed on the reduced solution, $\\forall v \\in \\mathbb{V}$:\n",
        "$$_{\\mathbb{V}'} \\langle r(\\boldsymbol{\\mu}), v  \\rangle_{\\mathbb{V}} = r(v; \\boldsymbol{\\mu}) := f(v; \\boldsymbol{\\mu}) - a(u_N(\\boldsymbol{\\mu}), v; \\boldsymbol{\\mu})$$\n",
        "\n",
        "From the error bound, we define \n",
        "$$Δ_N(\\boldsymbol{\\mu}) := \\frac{||r(\\boldsymbol{\\mu})||_{\\mathbb{V}'}}{\\beta^{\\mathcal{N}}(\\boldsymbol{\\mu})}$$\n",
        "\n",
        "To compute algebrically $Δ_N(\\boldsymbol{\\mu})$ we define the algebraic residual\n",
        "$$r^{\\mathcal{N}}(u_{N}; \\boldsymbol{\\mu}) := \\mathbb{f}(\\boldsymbol{\\mu}) - \\mathbb{A}(\\boldsymbol{\\mu}) \\mathbb{B} u_{N}(\\boldsymbol{\\mu})$$\n",
        "and we see from the definition that\n",
        "$$\\mathbb{A}(\\boldsymbol{\\mu}) e^{\\mathcal{N}}(\\boldsymbol{\\mu}) = r^{\\mathcal{N}}(u_{N}; \\boldsymbol{\\mu})$$\n",
        "****\n",
        "**Estimator $Δ_N(\\boldsymbol{\\mu})$ in $||\\cdot||_2$**\n",
        "\n",
        "Taking the $l^2$-norm on both side of the previous identity we obtain:\n",
        "$$||e^{\\mathcal{N}}(\\boldsymbol{\\mu})||_2 \\leq ||\\mathbb{A}^{-1}(\\boldsymbol{\\mu})||_2 ||r^{\\mathcal{N}}(u_{N}; \\boldsymbol{\\mu})||_2 = \\frac{1}{σ_{min}(\\mathbb{A}(\\boldsymbol{\\mu}))} ||r^{\\mathcal{N}}(u_{N}; \\boldsymbol{\\mu})||_2$$\n",
        "\n",
        "****\n",
        "**Estimator $Δ_N(\\boldsymbol{\\mu})$ in $||\\cdot||_{\\mathbb{X}^{-1}}$**\n",
        "\n",
        "Similarly as before, we multiply the previous identity by $\\mathbb{X}^{\\frac{1}{2}}$, thus :\n",
        "$$||\\mathbb{X}^{\\frac{1}{2}}e^{\\mathcal{N}}(\\boldsymbol{\\mu})||_2 \\leq ||\\mathbb{X}^{\\frac{1}{2}}\\mathbb{A}^{-1}(\\boldsymbol{\\mu})\\mathbb{X}^{\\frac{1}{2}}||_2 ||\\mathbb{X}^{-\\frac{1}{2}}r^{\\mathcal{N}}(u_{N}; \\boldsymbol{\\mu})||_2 = \\frac{1}{σ_{min}(\\mathbb{X}^{-\\frac{1}{2}}\\mathbb{A}(\\boldsymbol{\\mu})\\mathbb{X}^{-\\frac{1}{2}})} ||\\mathbb{X}^{-\\frac{1}{2}} r^{\\mathcal{N}}(u_{N}; \\boldsymbol{\\mu})||_2$$\n",
        "obtaining\n",
        "$$||e^{\\mathcal{N}}(\\boldsymbol{\\mu})||_{\\mathbb{X}} \\leq \\frac{1}{\\beta^{\\mathcal{N}}(\\boldsymbol{\\mu})}||r^{\\mathcal{N}}(u_{N}; \\boldsymbol{\\mu})||_{\\mathbb{X}^{-1}}$$\n",
        "as it is possible to show that $\\beta^{\\mathcal{N}}(\\boldsymbol{\\mu}) = σ_{min}(\\mathbb{X}^{-\\frac{1}{2}}\\mathbb{A}(\\boldsymbol{\\mu})\\mathbb{X}^{-\\frac{1}{2}})$ if $\\mathbb{A}(\\boldsymbol{\\mu})$ is symmetric.\n",
        "\n",
        "****\n",
        "**Offline-Online $Δ_N(\\boldsymbol{\\mu})$ Computation**\n",
        "\n",
        "If the affine assumption is valid, than\n",
        "\\begin{align}\n",
        "||r^{\\mathcal{N}}(u_{N}; \\boldsymbol{\\mu})||_{\\mathbb{X}^{-1}} = &\\sum_{q_1=1}^{q_f}\\sum_{q_2=1}^{q_f} \\theta_{q_1}^f(\\boldsymbol \\mu) \\theta_{q_2}^f(\\boldsymbol \\mu) \\underbrace{\\mathbf{f}^T_{q_1} \\mathbb{X}^{-1} \\mathbf{f}_{q_2}}_{C_{q_1, q_2}}\\\\\n",
        "- 2 &\\sum_{q_1=1}^{q_a}\\sum_{q_2=1}^{q_f} \\theta_{q_1}^a(\\boldsymbol \\mu) \\theta_{q_2}^f(\\boldsymbol \\mu) u^T_N(\\boldsymbol \\mu) \\underbrace{\\mathbb{B}^T\\mathbb{A}^T_{q_1} \\mathbb{X}^{-1} \\mathbf{f}_{q_2}}_{\\mathbf{d}_{q_1, q_2}}\\\\\n",
        "&\\sum_{q_1=1}^{q_a}\\sum_{q_2=1}^{q_a} \\theta_{q_1}^a(\\boldsymbol \\mu) \\theta_{q_2}^a(\\boldsymbol \\mu) u^T_N(\\boldsymbol \\mu) \\underbrace{\\mathbb{B}^T\\mathbb{A}^T_{q_1} \\mathbb{X}^{-1} \\mathbb{A}_{q_2}\\mathbb{B}}_{\\mathbb{E}_{q_1, q_2}} u_N(\\boldsymbol \\mu)\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "UjX6w1vDCnfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def OfflineResidual(AQH, fQH, B, invX):\n",
        "    Cq1q2 = [] \n",
        "    dq1q2 = []\n",
        "    Eq1q2 = []\n",
        "\n",
        "    for q1 in range(0, len(AQH)):\n",
        "        Z = invX.solve(AQH[q1] @ B)\n",
        "        \n",
        "        aqh_list = []\n",
        "        for q2 in range(0, len(AQH)):\n",
        "            aqh_list.append(np.copy(np.transpose(Z) @ AQH[q2] @ B))\n",
        "        Eq1q2.append(aqh_list.copy())\n",
        "        \n",
        "        fqh_list = []\n",
        "        for q2 in range(0, len(fQH)):\n",
        "            fqh_list.append(np.copy(np.transpose(Z) @ fQH[q2]))\n",
        "        dq1q2.append(fqh_list.copy())\n",
        "\n",
        "    for q1 in range(0, len(fQH)):\n",
        "        t = invX.solve(fQH[q1])\n",
        "        \n",
        "        fqh_list = []\n",
        "        for q2 in range(0, len(fQH)):\n",
        "            fqh_list.append(np.copy(np.transpose(t) @ fQH[q2]))\n",
        "        Cq1q2.append(fqh_list.copy())\n",
        "\n",
        "    return [Cq1q2, dq1q2, Eq1q2]\n",
        "    \n",
        "def InfSupConstant(mu):\n",
        "    return np.min(thetaA(mu))\n",
        "\n",
        "def ErrorEstimate(Cq1q2, dq1q2, Eq1q2, thetaA_mu, thetaF_mu, solN, beta):\n",
        "    fError = 0.0\n",
        "    for q1 in range(0, len(Cq1q2)):\n",
        "        for q2 in range(0, len(Cq1q2[q1])):\n",
        "            fError += thetaF_mu[q1] * thetaF_mu[q2] * Cq1q2[q1][q2]\n",
        "    \n",
        "    uError = 0.0\n",
        "    for q1 in range(0, len(Eq1q2)):\n",
        "        for q2 in range(0, len(Eq1q2[q1])):\n",
        "            uError += thetaA_mu[q1] * thetaA_mu[q2] * np.transpose(solN) @ Eq1q2[q1][q2] @ solN\n",
        "    \n",
        "    fuError = 0.0\n",
        "    for q1 in range(0, len(dq1q2)):\n",
        "        for q2 in range(0, len(dq1q2[q1])):\n",
        "            fuError += thetaA_mu[q1] * thetaF_mu[q2] * np.transpose(solN) @ dq1q2[q1][q2]\n",
        "    \n",
        "    deltaN_squared = fError - 2.0 * fuError + uError\n",
        "    if abs(deltaN_squared) <= 1.0e-12: # protect cancellation error\n",
        "        deltaN_squared = 0.0\n",
        "    elif deltaN_squared < 1.0e-12:\n",
        "      raise Exception('deltaN_squared is negative')\n",
        "    \n",
        "    return np.sqrt(deltaN_squared) / beta"
      ],
      "metadata": {
        "id": "5xp6PVOyzfH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Offline Phase\n"
      ],
      "metadata": {
        "id": "cCwwUAKRWi5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tol = 1.0e-7\n",
        "N_max = 20"
      ],
      "metadata": {
        "id": "uGvHXN1RW3E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform now the POD as for comparison:"
      ],
      "metadata": {
        "id": "sakp3wg6W5EN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwmcTXRtWi5K"
      },
      "outputs": [],
      "source": [
        "### Compute POD\n",
        "[N_POD, B_POD] = POD(AQH, fQH, X, N_max, tol)\n",
        "print(\"N_POD\", N_POD)\n",
        "\n",
        "[AQN_POD, fQN_POD] = ProjectSystem(AQH, fQH, B_POD)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the greedy with the same parameters"
      ],
      "metadata": {
        "id": "oAThS5IgW59_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Compute Greedy\n",
        "\n",
        "[N_Greedy, B_Greedy] = Greedy(AQH, fQH, X, N_max, tol)\n",
        "print(\"N_Greedy\", N_Greedy)\n",
        "\n",
        "[AQN_Greedy, fQN_Greedy] = ProjectSystem(AQH, fQH, B_Greedy)"
      ],
      "metadata": {
        "id": "k06Z9IfrzBWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcVTiQGqR-oz"
      },
      "source": [
        "### Online Phase\n",
        "\n",
        "In the _online phase_ we can use all the pre-assembled quantities to generate a new solution for a new parameter. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfINEnRbR_31"
      },
      "outputs": [],
      "source": [
        "thetaA2 = 2.\n",
        "thetaf1 = 0.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def TestSingleParameter(AQH, fQH, AQN, fQN, B, mu):\n",
        "    reduced_solution = Solve_reduced_order(AQN, fQN, thetaA(mu), thetaF(mu))\n",
        "    full_solution = Solve_full_order(AQH, fQH, thetaA(mu), thetaF(mu))\n",
        "\n",
        "    ###### plot #######\n",
        "    proj_reduced_solution = B @ reduced_solution\n",
        "\n",
        "    ### computing error\n",
        "    error_function = full_solution - proj_reduced_solution\n",
        "    error_norm_squared_component = np.transpose(error_function) @ X @ error_function\n",
        "    abs_err = np.sqrt(abs(error_norm_squared_component))\n",
        "\n",
        "    full_solution_norm_squared_component = np.transpose(full_solution) @  X @ full_solution\n",
        "    rel_err = abs_err / np.sqrt(abs(full_solution_norm_squared_component))\n",
        "\n",
        "    #gedim.PlotSolution(mesh, dofs, strongs, proj_reduced_solution, np.zeros(problemData['NumberStrongs']))\n",
        "    #gedim.PlotSolution(mesh, dofs, strongs, full_solution, np.zeros(problemData['NumberStrongs']))\n",
        "    \n",
        "    return [rel_err, abs_err]"
      ],
      "metadata": {
        "id": "ClnjLeqCmIJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdIlITaWSkRW"
      },
      "outputs": [],
      "source": [
        "[rel_err_POD, abs_err_POD] = TestSingleParameter(AQH, fQH, AQN_POD, fQN_POD, B_POD, [thetaA2, thetaf1])\n",
        "print(\"SingleParameter POD relative error = \", '{:.16e}'.format(np.mean(rel_err_POD)) )\n",
        "print(\"SingleParameter POD absolute error = \", '{:.16e}'.format(np.mean(abs_err_POD)) )\n",
        "\n",
        "[rel_err_Greedy, abs_err_Greedy] = TestSingleParameter(AQH, fQH, AQN_Greedy, fQN_Greedy, B_Greedy, [thetaA2, thetaf1])\n",
        "print(\"SingleParameter Gdy relative error = \", '{:.16e}'.format(np.mean(rel_err_Greedy)) )\n",
        "print(\"SingleParameter Gdy absolute error = \", '{:.16e}'.format(np.mean(abs_err_Greedy)) )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now compute an error analysis over the parametric space, together with a _speed-up_ anaslysis.\n",
        "\n",
        "The speed-up is an index that evaluated how many ROM solution I can obtain in the time of a FOM simulation."
      ],
      "metadata": {
        "id": "wol_tgKRmOyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Avg_error(AQH, fQH, AQN, fQN, B):\n",
        "    ### compute avg error\n",
        "    abs_err = []\n",
        "    rel_err = []\n",
        "    testing_set = np.random.uniform(low=P[:, 0], high=P[:, 1], size=(100, P.shape[0]))\n",
        "    speed_up = []\n",
        "\n",
        "    print(\"Computing error and speedup analysis...\")\n",
        "\n",
        "    for mu in testing_set:\n",
        "        ##### full #####\n",
        "        start_fom = time.time()\n",
        "        full_solution = Solve_full_order(AQH, fQH, thetaA(mu), thetaF(mu))\n",
        "        time_fom = time.time() - start_fom\n",
        "\n",
        "        #### reduced #####\n",
        "        start_rom = time.time()\n",
        "        reduced_solution = Solve_reduced_order(AQN, fQN, thetaA(mu), thetaF(mu))\n",
        "        time_rom = time.time() - start_rom\n",
        "\n",
        "        speed_up.append(time_fom / time_rom)\n",
        "\n",
        "        proj_reduced_solution = B @ reduced_solution\n",
        "\n",
        "        ### computing error\n",
        "        error_function = full_solution - proj_reduced_solution\n",
        "        error_norm_squared_component = np.transpose(error_function) @ X @ error_function\n",
        "        absolute_error = np.sqrt(abs(error_norm_squared_component))\n",
        "        abs_err.append(absolute_error)\n",
        "\n",
        "        full_solution_norm_squared_component = np.transpose(full_solution) @  X @ full_solution\n",
        "        relative_error = absolute_error/np.sqrt(abs(full_solution_norm_squared_component))\n",
        "        rel_err.append(relative_error)\n",
        "    \n",
        "    return [rel_err, abs_err, speed_up]"
      ],
      "metadata": {
        "id": "Il8bS-Al16SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[rel_err_POD, abs_err_POD, speed_up_POD] = Avg_error(AQH, fQH, AQN_POD, fQN_POD, B_POD)\n",
        "print(\"- Average POD relative error = \", '{:.16e}'.format(np.mean(rel_err_POD)) )\n",
        "print(\"- Average POD absolute error = \", '{:.16e}'.format(np.mean(abs_err_POD)) )\n",
        "print(\"- Average POD speed_up       = \", '{:.16e}'.format(np.mean(speed_up_POD)))\n",
        "\n",
        "[rel_err_Greedy, abs_err_Greedy, speed_up_Greedy] = Avg_error(AQH, fQH, AQN_Greedy, fQN_Greedy, B_Greedy)\n",
        "print(\"- Average Gdy relative error = \", '{:.16e}'.format(np.mean(rel_err_Greedy)) )\n",
        "print(\"- Average Gdy absolute error = \", '{:.16e}'.format(np.mean(abs_err_Greedy)) )\n",
        "print(\"- Average Gdy speed_up       = \", '{:.16e}'.format(np.mean(speed_up_Greedy)))"
      ],
      "metadata": {
        "id": "oxQFFzPdt7nE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}