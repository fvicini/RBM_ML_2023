{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IGuNCbv2QpF"
      },
      "source": [
        "# **Stokes and Supremizer Stabilization**\n",
        "In a Stokes problem, in order to guarantee the well-posedness, we have to prove:\n",
        "\n",
        "1. The coercivity of the grad-grad form over the kernel of the divergence operator.\n",
        "2. The divergence operator has to verify the inf-sup stability condition, namely:\n",
        "$$\n",
        "\\beta_{\\delta}(\\mu) = \\inf_{\\mathsf q \\neq 0} \\sup_{\\mathsf v \\neq 0} \n",
        "\\frac{\\mathsf q^T B \\mathsf v}{\\vert \\vert \\mathsf q \\vert \\vert \\vert \\vert \\mathsf v \\vert \\vert } > 0.\n",
        "$$ \n",
        "\n",
        "The inf-sup relation means that $\\mathsf{ker}(B^T) = \\{0\\}$ (no pressures different from zero let the divergence to be null).\n",
        "\n",
        "In the FE setting, the above relation is verified with some special combinations of spaces, like the **Taylor-Hood** approximation: namely $\\mathbb P^2$ elements for velocity and $\\mathbb P^1$ for pressure (also called $\\mathbb P^2- \\mathbb P^1$ elements).\n",
        "\n",
        "How does it translates in the reduced framework?\n",
        "\n",
        "Property 1. is directly inherited from the FE discretization, and property 2. reads:\n",
        "\n",
        "$$\n",
        "\\beta_{N}(\\mu) = \\inf_{\\mathsf q_{N_p} \\neq 0} \\sup_{\\mathsf v_{N_u} \\neq 0} \n",
        "\\frac{\\mathsf q_{N_p}^T B_{N} \\mathsf v_{N_u}}{\\vert \\vert \\mathsf q \\vert \\vert \\vert \\vert \\mathsf v \\vert \\vert } > 0.\n",
        "$$ \n",
        "\n",
        "It is clear that, in general, for reduced problems, the inf-sup condition is not fulfilled. Let us consider a reduced basis $\\{\\phi_i\\}_{i=1}^{N_u}$ and $\\{\\psi_i\\}_{i=1}^{N_p}$, for velocity and pressure, respectively. \n",
        "The matrix $[B_N]_{kj} = b(\\phi_k, \\psi_j) = 0$, since the velocity basis functions are conbination of weakly-divergence-free snapshots.\n",
        "\n",
        "Namely $\\mathsf{ker}(B_N^T) \\neq \\{0\\}$, indeed, it is definetely larger, since every pressure basis is actually an element of the kernel!\n",
        "\n",
        "To avoid this problem we use _supremizer stabilization_. \n",
        "\n",
        "From now on, we suppose $N_p = N_u = N$, just for a simpler presentation of the topic.\n",
        "\n",
        "The trick is to enrich the velocity space with the following vector field $\\mathsf s^{\\mu}$ for each pressure mode and each related parametric instance:\n",
        "$$\n",
        "\\mathbb X_u \\mathsf s^{\\mu}(\\overline{\\psi}_j) = B^T\\overline{\\psi}_j,\n",
        "$$\n",
        "where $\\overline{\\psi}_j$ is the FE vector related to the pressure basis. The vector field $\\mathsf s^{\\mu}(q)$ is called **supremizer** and it is defined as\n",
        "\n",
        "$$\n",
        "\\mathsf  s^{\\mu}(q) = {\\arg \\sup}_{\\mathsf v \\neq 0} \n",
        "\\frac{\\mathsf q_N^T B \\mathsf v}{\\vert \\vert \\mathsf v \\vert \\vert }.\n",
        "$$\n",
        "\n",
        "Indeed, in this way, we can prove the following relation:\n",
        "\n",
        "$$\n",
        "0 < \\beta_{\\delta}(\\mu)  = \\inf_{\\mathsf q \\neq 0} \\sup_{\\mathsf v \\neq 0} \n",
        "\\frac{\\mathsf q^T B \\mathsf v}{\\vert \\vert \\mathsf q \\vert \\vert \\vert \\vert \\mathsf v \\vert \\vert } \\leq \n",
        "\\inf_{\\mathsf q_N \\neq 0} \\sup_{\\mathsf v \\neq 0} \n",
        "\\frac{(\\mathbb B_p\\mathsf q_N)^T B \\mathsf v}{\\vert \\vert \\mathbb B_p\\mathsf q_N \\vert \\vert \\vert \\vert \\mathsf v \\vert \\vert } \\leq \n",
        "\\inf_{\\mathsf q_N \\neq 0} \n",
        " \\frac{(\\mathbb B_p\\mathsf q_N)^T B \\mathsf s^{\\mu}(\\mathbb B_p\\mathsf q_N)}{\\vert \\vert \\mathbb B_p\\mathsf q_N \\vert \\vert \\vert \\vert \\mathsf s^{\\mu}(\\mathbb B_p\\mathsf q_N)\\vert \\vert } \\leq\n",
        " \\inf_{\\mathsf q_N \\neq 0} \\sup_{\\mathsf v_N \\neq 0} \n",
        "\\frac{\\mathsf q_N^T\\mathbb B_p^T B  \\mathbb B_u \\mathsf v_N}{\\vert \\vert \\mathbb B_p\\mathsf q_N \\vert \\vert \\vert \\vert \\mathbb B_u \\mathsf v_N \\vert \\vert } = \\inf_{\\mathsf q_N \\neq 0} \\sup_{\\mathsf v_N \\neq 0} \n",
        "\\frac{\\mathsf q_N^T B_N\\mathsf v_N}{\\vert \\vert \\mathsf q_N \\vert \\vert \\vert \\vert \\mathsf v_N \\vert \\vert} = \\beta_{N}(\\mu).\n",
        "$$ \n",
        "\n",
        "Let us understand how to exploit these notions on the creation of the reduced space.\n",
        "\n",
        "**Be careful**: you can see that the supremizer stabilization depends _online_ on the FOM dimension $N_{\\delta}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOKm4Cpr0agg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/fvicini/CppToPython.git\n",
        "%cd CppToPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVlYTB8mifCl"
      },
      "outputs": [],
      "source": [
        "!git submodule init\n",
        "!git submodule update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xezfpm75i_FG"
      },
      "outputs": [],
      "source": [
        "!mkdir -p externals\n",
        "%cd externals\n",
        "!cmake -DINSTALL_VTK=OFF -DINSTALL_LAPACK=OFF ../gedim/3rd_party_libraries\n",
        "!make -j4\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LamP-IF1tLt"
      },
      "outputs": [],
      "source": [
        "!mkdir -p release\n",
        "%cd release \n",
        "!cmake -DCMAKE_PREFIX_PATH=\"/content/CppToPython/externals/Main_Install/eigen3;/content/CppToPython/externals/Main_Install/triangle;/content/CppToPython/externals/Main_Install/tetgen;/content/CppToPython/externals/Main_Install/googletest\" ../\n",
        "!make -j4 GeDiM4Py\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeaV-lky4gkR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import GeDiM4Py as gedim\n",
        "from scipy.sparse.linalg import splu\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13zM04WMQ5hJ"
      },
      "outputs": [],
      "source": [
        "lib = gedim.ImportLibrary(\"./release/GeDiM4Py.so\")\n",
        "\n",
        "config = { 'GeometricTolerance': 1.0e-8 }\n",
        "gedim.Initialize(config, lib)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubq1Ge_iQkak"
      },
      "source": [
        "## The parametric version of the Stokes problem\n",
        "\n",
        "Solve the Stokes equation on square ${\\Omega} = (0, 1) \\times (0, 1)$\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "-\\mu_1 \\nabla \\cdot (\\nabla \\mathbf{u}) + \\nabla p = \\mathbf{f} & \\text{in } \\Omega\\\\\n",
        "(\\nabla \\cdot \\mathbf{u}) = 0 & \\text{in } \\Omega\\\\\n",
        "u = 0 & \\text{in } âˆ‚ \\Omega\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where $\\nu$ is the **viscosity**, $\\mathbf{u} = (u_1, u_2)$ is the **speed** and $p$ is the **pressure**, with $\\mathbf{f}$ a parametric version of the forcing term of Lab10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOPeoKRlRNMo"
      },
      "outputs": [],
      "source": [
        "def Stokes_V():\n",
        "\treturn 1.0\n",
        "\n",
        "def Stokes_v(numPoints, points):\n",
        "\tvalues = np.ones(numPoints) * Stokes_V()\n",
        "\treturn values.ctypes.data\n",
        "\n",
        "def Stokes_advection_1(numPoints, points):\n",
        "\tvalues = np.zeros((2, numPoints), order='F')\n",
        "\tvalues[0,:] = 1.0\n",
        "\treturn values.ctypes.data\n",
        "\n",
        "def Stokes_advection_2(numPoints, points):\n",
        "\tvalues = np.zeros((2, numPoints), order='F')\n",
        "\tvalues[1,:] = 1.0\n",
        "\treturn values.ctypes.data\n",
        "############## Forcing term WRT mu_2 #####################\n",
        "def Stokes_f_1(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = - ((mu_2**3) * np.pi * np.pi * np.cos((mu_2**2)* np.pi * matPoints[0,:]) - (mu_2**2) * np.pi * np.pi) * np.sin(mu_2 * np.pi * matPoints[1,:]) * np.cos(mu_2 * np.pi * matPoints[1,:]) + (+mu_2 * np.pi * np.cos(mu_2 * np.pi * matPoints[0,:]) * np.cos(mu_2 * np.pi * matPoints[1,:]))\n",
        "\treturn values.ctypes.data\n",
        "\n",
        "def Stokes_f_2(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = - (-(mu_2**3) * np.pi * np.pi * np.cos((mu_2**2) * np.pi * matPoints[1,:]) + (mu_2**2) * np.pi * np.pi) * np.sin(mu_2 * np.pi * matPoints[0,:]) * np.cos(mu_2 * np.pi * matPoints[0,:]) + (-mu_2* np.pi * np.sin(mu_2 * np.pi * matPoints[0,:]) * np.sin(mu_2 * np.pi * matPoints[1,:]))\n",
        "\treturn values.ctypes.data\n",
        "#############\n",
        "def Stokes_pressure_exactSolution(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = np.sin(2.0 * np.pi * matPoints[0,:]) * np.cos(2.0 * np.pi * matPoints[1,:])\n",
        "\treturn values.ctypes.data\n",
        "\n",
        "def Stokes_speed_exactSolution_1(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = +0.5 * np.sin(2.0 * np.pi * matPoints[0,:]) * np.sin(2.0 * np.pi * matPoints[0,:]) * np.sin(2.0 * np.pi * matPoints[1,:]) * np.cos(2.0 * np.pi * matPoints[1,:])\n",
        "\treturn values.ctypes.data\n",
        "\n",
        "def Stokes_speed_exactSolution_2(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = -0.5 * np.sin(2.0 * np.pi * matPoints[1,:]) * np.sin(2.0 * np.pi * matPoints[1,:]) * np.sin(2.0 * np.pi * matPoints[0,:]) * np.cos(2.0 * np.pi * matPoints[0,:])\n",
        "\treturn values.ctypes.data"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mNHi_cfVVbXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discretization"
      ],
      "metadata": {
        "id": "OPb1VMnR6XOn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfzHSAXORH5X"
      },
      "outputs": [],
      "source": [
        "order = 1\n",
        "meshSize = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFrwWHkGRTcM"
      },
      "outputs": [],
      "source": [
        "domain = { 'SquareEdge': 1.0, 'VerticesBoundaryCondition': [1,1,1,1], 'EdgesBoundaryCondition': [2,3,4,5], 'DiscretizationType': 1, 'MeshCellsMaximumArea': meshSize }\n",
        "[meshInfo, mesh] = gedim.CreateDomainSquare(domain, lib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FifaSs5tRWLp"
      },
      "outputs": [],
      "source": [
        "gedim.PlotMesh(mesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFLs55ZIRjRw"
      },
      "source": [
        "### High Fidelity approximation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtVL7IqnRlra"
      },
      "outputs": [],
      "source": [
        "pressure_discreteSpace = { 'Order': 1, 'Type': 1, 'BoundaryConditionsType': [1, 2, 1, 1, 1, 1] }\n",
        "speed_discreteSpace = { 'Order': 2, 'Type': 1, 'BoundaryConditionsType': [1, 2, 2, 2, 2, 2] }\n",
        "\n",
        "[pressure_problemData, pressure_dofs, pressure_strongs] = gedim.Discretize(pressure_discreteSpace, lib)\n",
        "[speed_problemData, speed_dofs, speed_strongs] = gedim.Discretize(speed_discreteSpace, lib)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mFZeN2YdsxFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pressure_n_dofs = pressure_problemData['NumberDOFs']\n",
        "pressure_n_strongs = pressure_problemData['NumberStrongs']\n",
        "speed_n_dofs = speed_problemData['NumberDOFs']\n",
        "speed_n_strongs = speed_problemData['NumberStrongs']"
      ],
      "metadata": {
        "id": "arSjIf883qjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[J_X_1, J_X_D_1] = gedim.AssembleStiffnessMatrix_Shift(speed_problemData['SpaceIndex'], speed_problemData['SpaceIndex'], Stokes_v, 2 * speed_n_dofs + pressure_n_dofs, 2 * speed_n_dofs + pressure_n_dofs, 2 * speed_n_strongs + pressure_n_strongs, 0, 0, 0, lib)\n",
        "[J_X_2, J_X_D_2] = gedim.AssembleStiffnessMatrix_Shift(speed_problemData['SpaceIndex'], speed_problemData['SpaceIndex'], Stokes_v, 2 * speed_n_dofs + pressure_n_dofs, 2 * speed_n_dofs + pressure_n_dofs, 2 * speed_n_strongs + pressure_n_strongs, speed_n_dofs, speed_n_dofs, speed_n_strongs, lib)\n",
        "\n",
        "[J_B_1, J_B_D_1] = gedim.AssembleAdvectionMatrix_Shift(speed_problemData['SpaceIndex'], pressure_problemData['SpaceIndex'], Stokes_advection_1, 2 * speed_n_dofs + pressure_n_dofs, 2 * speed_n_dofs + pressure_n_dofs, 2 * speed_n_strongs + pressure_n_strongs, 2 * speed_n_dofs, 0, 0, lib)\n",
        "[J_B_2, J_B_D_2] = gedim.AssembleAdvectionMatrix_Shift(speed_problemData['SpaceIndex'], pressure_problemData['SpaceIndex'], Stokes_advection_2, 2 * speed_n_dofs + pressure_n_dofs, 2 * speed_n_dofs + pressure_n_dofs, 2 * speed_n_strongs + pressure_n_strongs, 2 * speed_n_dofs, speed_n_dofs, speed_n_strongs, lib)\n",
        "mu_2 = 2\n",
        "J_f_1 = gedim.AssembleForcingTerm(Stokes_f_1, speed_problemData, lib)\n",
        "J_f_2 = gedim.AssembleForcingTerm(Stokes_f_2, speed_problemData, lib)\n",
        "J_f = np.concatenate([J_f_1, J_f_2, np.zeros(pressure_n_dofs)])\n",
        "\n",
        "p_D = gedim.AssembleStrongSolution(Stokes_pressure_exactSolution, 1, pressure_problemData, lib)"
      ],
      "metadata": {
        "id": "ubj0jpkjs2ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solution = gedim.LUSolver(J_X_1 + J_X_2 - J_B_1 - J_B_2 - np.transpose(J_B_1) - np.transpose(J_B_2), J_f, lib)\n",
        "u = solution[0:2 * speed_n_dofs]\n",
        "p = solution[2 * speed_n_dofs:]"
      ],
      "metadata": {
        "id": "HFi188Mks-ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gedim.PlotSolution(mesh, pressure_dofs, pressure_strongs, p, p_D, \"Pressure\")\n",
        "gedim.PlotSolution(mesh, speed_dofs, speed_strongs, u[0:speed_n_dofs], np.zeros(speed_n_strongs), \"Speed X\")\n",
        "gedim.PlotSolution(mesh, speed_dofs, speed_strongs, u[speed_n_dofs:], np.zeros(speed_n_strongs), \"Speed Y\")\n",
        "gedim.PlotSolution(mesh, speed_dofs, speed_strongs, np.sqrt(u[0:speed_n_dofs] * u[0:speed_n_dofs] + u[speed_n_dofs:] * u[speed_n_dofs:]), np.zeros(speed_n_strongs), \"Speed Magnitude\")"
      ],
      "metadata": {
        "id": "HxSjMxigv6Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define the parameters for the POD, i.e. the snapshot number and the parametric space."
      ],
      "metadata": {
        "id": "WYyTVdVYwopj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2dzS4-3dZm2"
      },
      "outputs": [],
      "source": [
        "### define the training set\n",
        "\n",
        "snapshot_num = 100\n",
        "mu1_range = [1., 10.]\n",
        "mu2_range = [1., 3.]\n",
        "P = np.array([mu1_range, mu2_range])\n",
        "\n",
        "training_set = np.random.uniform(low=P[:, 0], high=P[:, 1], size=(snapshot_num, P.shape[0]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we define the matrices needed to compute the supremizer for each solution of the Stokes problem."
      ],
      "metadata": {
        "id": "hB8Jziiyw3Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[X_1, XStrong_1] = gedim.AssembleStiffnessMatrix_Shift(speed_problemData['SpaceIndex'], speed_problemData['SpaceIndex'], Stokes_v, 2 * speed_n_dofs, 2 * speed_n_dofs, 2 * speed_n_strongs, 0, 0, 0, lib)\n",
        "[X_2, XStrong_2] = gedim.AssembleStiffnessMatrix_Shift(speed_problemData['SpaceIndex'], speed_problemData['SpaceIndex'], Stokes_v, 2 * speed_n_dofs, 2 * speed_n_dofs, 2 * speed_n_strongs, speed_n_dofs, speed_n_dofs, speed_n_strongs, lib)\n",
        "\n",
        "[B_1, BStrong_1] = gedim.AssembleAdvectionMatrix_Shift(speed_problemData['SpaceIndex'], pressure_problemData['SpaceIndex'], Stokes_advection_1, pressure_n_dofs, 2 * speed_n_dofs, 2 * speed_n_strongs, 0, 0, 0, lib)\n",
        "[B_2, BStrong_2] = gedim.AssembleAdvectionMatrix_Shift(speed_problemData['SpaceIndex'], pressure_problemData['SpaceIndex'], Stokes_advection_2, pressure_n_dofs, 2 * speed_n_dofs, 2 * speed_n_strongs, 0, speed_n_dofs, speed_n_strongs, lib)"
      ],
      "metadata": {
        "id": "DhelSIQP5BiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply the **partitioned POD**. Nemely, we apply a POD for each of the _three_ variables of the Stokes equations.\n",
        "\n",
        "**Question time!** why three?\n",
        "\n",
        "If we apply three different PODs, we need three different snapshots matrices.\n",
        "Usually, computing the supremizer for all the pressure modes retained is not feasable (FE offline), thus, we use the _inexact supremizer_. We compute the supremizers for the snapshots that we already have and we perform the POD on the supremizer snapshots, too. The basis will be added in the projection phase.\n",
        "\n",
        "Experimentally has been verified that it is a valid strategy to avoid $N_{\\delta}-$dependent computations on the online phase."
      ],
      "metadata": {
        "id": "WWaAY-aDxLX-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJDt8TvQdW8Z"
      },
      "outputs": [],
      "source": [
        "#### snapshot matrices creation\n",
        "\n",
        "snapshot_matrix_u = []\n",
        "snapshot_matrix_s = [] ### supremizer snapshot\n",
        "snapshot_matrix_p = []\n",
        "\n",
        "tol = 1. - 1e-7\n",
        "N_max = 20\n",
        "\n",
        "for mu in training_set:\n",
        "  thetaA1 = mu[0]\n",
        "  mu_2 = mu[1]\n",
        "  \n",
        "  #### the problem is not affine: I have to assemble in this stage!! ###\n",
        "  J_f_1 = gedim.AssembleForcingTerm(Stokes_f_1, speed_problemData, lib)\n",
        "  J_f_2 = gedim.AssembleForcingTerm(Stokes_f_2, speed_problemData, lib)\n",
        "  J_f = np.concatenate([J_f_1, J_f_2, np.zeros(pressure_n_dofs)])\n",
        "  lhs = thetaA1*(J_X_1 + J_X_2) - J_B_1 - J_B_2 - np.transpose(J_B_1) - np.transpose(J_B_2)\n",
        "  rhs = J_f\n",
        "  \n",
        "  snapshot_solution = gedim.LUSolver(lhs, rhs, lib)\n",
        "  \n",
        "  snapshot_u = snapshot_solution[0:2 * speed_n_dofs]\n",
        "  snapshot_matrix_u.append(np.copy(snapshot_u))\n",
        "  \n",
        "  snapshot_p = snapshot_solution[2 * speed_n_dofs:]\n",
        "  snapshot_matrix_p.append(np.copy(snapshot_p))\n",
        "\n",
        "  snapshot_s = gedim.LUSolver(X_1 + X_2, np.transpose(B_1 + B_2) @ snapshot_p, lib)\n",
        "  snapshot_matrix_s.append(np.copy(snapshot_s))\n",
        "\n",
        "  \n",
        "  \n",
        " \n",
        "\n",
        "snapshot_matrix_u = np.array(snapshot_matrix_u) \n",
        "\n",
        "snapshot_matrix_s = np.array(snapshot_matrix_s) \n",
        "\n",
        "snapshot_matrix_p = np.array(snapshot_matrix_p) \n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the sake of clarity, let us recall the inner products.\n",
        "\n",
        "**Question time!** why am I defining only the inner product for the velocity?"
      ],
      "metadata": {
        "id": "r8Sv9t-w2RoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inner_product_u = X_1 + X_2"
      ],
      "metadata": {
        "id": "L2afHeSNG4dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we define a function that, given a covariance matrix (the maximum number of basis functions and a tolerance) computes the related eigenvalues and eigenvectors, returns the eigenvectors and the basis number."
      ],
      "metadata": {
        "id": "X92J1zs_4Hrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eig_analysis(C, N_max=None, tol=1e-9):\n",
        "  L_e, VM_e = np.linalg.eig(C)\n",
        "  eigenvalues = []\n",
        "  eigenvectors = []\n",
        "\n",
        "\n",
        "  #### check\n",
        "\n",
        "  for i in range(len(L_e)):\n",
        "    eig_real = L_e[i].real\n",
        "    eig_complex = L_e[i].imag\n",
        "    assert np.isclose(eig_complex, 0.)\n",
        "    eigenvalues.append(eig_real)\n",
        "    eigenvectors.append(VM_e[i].real)\n",
        "\n",
        "\n",
        "  total_energy = sum(eigenvalues)\n",
        "  retained_energy_vector = np.cumsum(eigenvalues)\n",
        "  relative_retained_energy = retained_energy_vector/total_energy\n",
        "\n",
        "\n",
        "  if all(flag==False for flag in relative_retained_energy>= tol) and N_max != None:\n",
        "    N = N_max\n",
        "  else:\n",
        "    N = np.argmax(relative_retained_energy >= tol) + 1\n",
        "  \n",
        "  return N, eigenvectors\n",
        "\n"
      ],
      "metadata": {
        "id": "aMCf0bkbQXKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VxLRw6TgNM9"
      },
      "outputs": [],
      "source": [
        "### covariance matrix\n",
        "\n",
        "C_u = snapshot_matrix_u @ inner_product_u @ np.transpose(snapshot_matrix_u)\n",
        "C_s = snapshot_matrix_s @ inner_product_u @ np.transpose(snapshot_matrix_s)\n",
        "C_p = snapshot_matrix_p @ np.transpose(snapshot_matrix_p)\n",
        "\n",
        "N_u, eigs_u = eig_analysis(C_u, N_max=N_max, tol=tol)\n",
        "N_s, eigs_s = eig_analysis(C_s, N_max=N_max, tol=tol)\n",
        "N_p, eigs_p = eig_analysis(C_p, N_max=N_max, tol=tol)\n",
        "\n",
        "print(N_u, N_s, N_p)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create a function that creates the basis, given the snapshots matrix, the reduced dimension and the eigenvectors."
      ],
      "metadata": {
        "id": "ya30YDYV5_Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_basis_functions_matrix(N, snapshot_matrix, eigenvectors, inner_product=None):\n",
        "  \n",
        "  basis_functions = []\n",
        "  \n",
        "  for n in range(N):\n",
        "    eigenvector =  eigenvectors[n]\n",
        "    basis = np.transpose(snapshot_matrix)@eigenvector\n",
        "    if inner_product!= None:\n",
        "      norm = np.sqrt(np.transpose(basis) @ inner_product @ basis) ## metti inner product\n",
        "    else:\n",
        "      norm = np.sqrt(np.transpose(basis) @ basis)\n",
        "    basis /= norm\n",
        "    basis_functions.append(np.copy(basis))\n",
        "\n",
        "  basis_function_matrix = np.transpose(np.array(basis_functions))\n",
        "  \n",
        "  return basis_function_matrix"
      ],
      "metadata": {
        "id": "8DBrdWGaR35F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create three separate basis functions and then the global basis function that we need for the projection:\n",
        "\n",
        "$$\\mathbb {B} = \n",
        "\\begin{bmatrix} \\mathbb B_u \\cup \\mathbb B_s & 0\\\\\n",
        "0 & \\mathbb B_p\n",
        "\\end{bmatrix}.$$\n"
      ],
      "metadata": {
        "id": "xYMlbFhpWb1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basis_functions_u = create_basis_functions_matrix(N_u, snapshot_matrix_u, eigs_u, inner_product=inner_product_u)\n",
        "basis_functions_s = create_basis_functions_matrix(N_s, snapshot_matrix_s, eigs_s, inner_product=inner_product_u)\n",
        "basis_functions_p = create_basis_functions_matrix(N_p, snapshot_matrix_p, eigs_p)\n"
      ],
      "metadata": {
        "id": "w6bVl8hxjM56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(basis_functions_u.shape)\n",
        "print(basis_functions_p.shape)\n",
        "print(basis_functions_u.shape[0] + basis_functions_p.shape[0])\n",
        "print(basis_functions_p.shape)\n",
        "print(solution.shape)\n",
        "\n",
        "global_basis_function_matrix = np.zeros((basis_functions_u.shape[0] + basis_functions_p.shape[0],N_u + N_s + N_p))\n",
        "global_basis_function_matrix[0:basis_functions_u.shape[0], 0:N_u] = basis_functions_u\n",
        "global_basis_function_matrix[0:basis_functions_u.shape[0], N_u : N_u + N_s] = basis_functions_s\n",
        "global_basis_function_matrix[basis_functions_u.shape[0]:, N_u + N_s:] = basis_functions_p\n",
        "print(global_basis_function_matrix.shape)\n",
        "\n",
        "global_basis_function_matrix_no_sipremizer = np.zeros((basis_functions_u.shape[0] + basis_functions_p.shape[0],N_u + N_p))\n",
        "global_basis_function_matrix_no_sipremizer[0:basis_functions_u.shape[0], 0:N_u] = basis_functions_u\n",
        "global_basis_function_matrix_no_sipremizer[basis_functions_u.shape[0]:, N_u:] = basis_functions_p"
      ],
      "metadata": {
        "id": "bDCdmymWjl_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now define the assemble-functions"
      ],
      "metadata": {
        "id": "pwd5IA1US-Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assemble_reduced_matrix(basis, fom_matrix):\n",
        "  return np.transpose(basis) @ (fom_matrix) @ basis\n",
        "\n",
        "def assemble_reduced_vector(basis, fom_vector):\n",
        "  return np.transpose(basis) @ (fom_vector)"
      ],
      "metadata": {
        "id": "_JiR46UNxt3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us finish the offline phase"
      ],
      "metadata": {
        "id": "CnHv5StfTfW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ASSEMBLE REDUCED SYSTEMS\n",
        "reduced_stiff_Stokes = assemble_reduced_matrix(global_basis_function_matrix, (J_X_1 + J_X_2)) \n",
        "reduced_divergence_operator_1 = assemble_reduced_matrix(global_basis_function_matrix, (J_B_1)) \n",
        "reduced_divergence_operator_2 = assemble_reduced_matrix(global_basis_function_matrix, (J_B_2))\n",
        "\n"
      ],
      "metadata": {
        "id": "xy2n97laq1mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are ready for a new evaluation!"
      ],
      "metadata": {
        "id": "liEy2OULUC0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### New eval\n",
        "thetaA1 = 1\n",
        "mu_2 = 2\n",
        "J_f_1 = gedim.AssembleForcingTerm(Stokes_f_1, speed_problemData, lib)\n",
        "J_f_2 = gedim.AssembleForcingTerm(Stokes_f_2, speed_problemData, lib)\n",
        "J_f = np.concatenate([J_f_1, J_f_2, np.zeros(pressure_n_dofs)])\n",
        "reduced_lhs = thetaA1*reduced_stiff_Stokes - reduced_divergence_operator_1 - reduced_divergence_operator_2 - np.transpose(reduced_divergence_operator_1) - np.transpose(reduced_divergence_operator_2)\n",
        "reduced_rhs = assemble_reduced_vector(global_basis_function_matrix, J_f)"
      ],
      "metadata": {
        "id": "cypk3_4SuhV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_solution = np.linalg.solve(reduced_lhs, reduced_rhs)\n",
        "print(reduced_solution)"
      ],
      "metadata": {
        "id": "X5n2MB8qu1xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### plot #######\n",
        "reduced_u_dof = N_u + N_s\n",
        "# reduced_p_dof = N_p\n",
        "reduced_solution_FE_basis = global_basis_function_matrix @ reduced_solution\n",
        "reduced_u = reduced_solution_FE_basis[0:2*speed_n_dofs]\n",
        "reduced_p = reduced_solution_FE_basis[2*speed_n_dofs:]\n",
        "\n",
        "gedim.PlotSolution(mesh, pressure_dofs, pressure_strongs, reduced_p, p_D, \"Pressure\")\n",
        "gedim.PlotSolution(mesh, speed_dofs, speed_strongs, np.sqrt(reduced_u[0:speed_n_dofs] * reduced_u[0:speed_n_dofs] + reduced_u[speed_n_dofs:] * reduced_u[speed_n_dofs:]), np.zeros(speed_n_strongs), \"Speed Magnitude\")\n"
      ],
      "metadata": {
        "id": "WDc7todEvLgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What happens without supremizer?**"
      ],
      "metadata": {
        "id": "899tCh-1VZuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### NO SUPREMIZER\n",
        "reduced_stiff_Stokes_nsup = assemble_reduced_matrix(global_basis_function_matrix_no_sipremizer, (J_X_1 + J_X_2)) # np.transpose(global_basis_function_matrix) @ (J_X_1 + J_X_2) @ global_basis_function_matrix\n",
        "reduced_divergence_operator_1_nsup = assemble_reduced_matrix(global_basis_function_matrix_no_sipremizer, (J_B_1)) #np.transpose(global_basis_function_matrix) @ J_B_1 @ global_basis_function_matrix\n",
        "reduced_divergence_operator_2_nsup = assemble_reduced_matrix(global_basis_function_matrix_no_sipremizer, (J_B_2))\n",
        "# - J_B_1 - J_B_2\n"
      ],
      "metadata": {
        "id": "FXKgI_r-0tpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### New eval\n",
        "reduced_lhs = thetaA1*reduced_stiff_Stokes_nsup - reduced_divergence_operator_1_nsup - reduced_divergence_operator_2_nsup - np.transpose(reduced_divergence_operator_1_nsup) - np.transpose(reduced_divergence_operator_2_nsup)\n",
        "reduced_rhs = assemble_reduced_vector(global_basis_function_matrix_no_sipremizer, J_f)"
      ],
      "metadata": {
        "id": "h9MNnSE50tpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_solution = np.linalg.solve(reduced_lhs, reduced_rhs)\n",
        "print(reduced_solution)"
      ],
      "metadata": {
        "id": "rInX7UAZ0tpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### plot #######\n",
        "reduced_u_dof = N_u + N_s\n",
        "# reduced_p_dof = N_p\n",
        "reduced_solution_FE_basis = global_basis_function_matrix_no_sipremizer @ reduced_solution\n",
        "reduced_u = reduced_solution_FE_basis[0:2*speed_n_dofs]\n",
        "reduced_p = reduced_solution_FE_basis[2*speed_n_dofs:]\n",
        "\n",
        "gedim.PlotSolution(mesh, pressure_dofs, pressure_strongs, reduced_p, p_D, \"Pressure\")\n",
        "gedim.PlotSolution(mesh, speed_dofs, speed_strongs, np.sqrt(reduced_u[0:speed_n_dofs] * reduced_u[0:speed_n_dofs] + reduced_u[speed_n_dofs:] * reduced_u[speed_n_dofs:]), np.zeros(speed_n_strongs), \"Speed Magnitude\")\n"
      ],
      "metadata": {
        "id": "Ja3ccQI40tpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us analyze the usual stuff: errors and speedups!\n",
        "Below you find a function that computes the error."
      ],
      "metadata": {
        "id": "GyPuy-W5VXx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######### def error functions ######\n",
        "\n",
        "def compute_error(fom_solution, rom_solution_FE_basis, inner_product=None, type_err=\"relative\"):\n",
        "    \n",
        "    error_function_u = fom_solution - rom_solution_FE_basis\n",
        "    \n",
        "    if inner_product == None:\n",
        "        inner_product_matrix = np.identity(fom_solution.shape[0])\n",
        "    else:\n",
        "      print()\n",
        "      inner_product_matrix = inner_product\n",
        "    \n",
        "    error_norm_squared_component = np.transpose(error_function_u) @ inner_product_matrix @ error_function_u\n",
        "    absolute_error = np.sqrt(abs(error_norm_squared_component))\n",
        "    \n",
        "    if type_err == \"absolute\":\n",
        "      \n",
        "      return absolute_error\n",
        "    \n",
        "    else:\n",
        "      full_solution_norm_squared_component = np.transpose(fom_solution) @  inner_product_matrix @ fom_solution\n",
        "      relative_error = absolute_error/np.sqrt(abs(full_solution_norm_squared_component))\n",
        "    \n",
        "      return relative_error\n",
        "    "
      ],
      "metadata": {
        "id": "A-5xvlRY7WVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw3uJvR-o4fD"
      },
      "outputs": [],
      "source": [
        "### compute error\n",
        "import time\n",
        "\n",
        "abs_err_u = []\n",
        "rel_err_u = []\n",
        "\n",
        "abs_err_p = []\n",
        "rel_err_p = []\n",
        "\n",
        "testing_set = np.random.uniform(low=P[:, 0], high=P[:, 1], size=(100, P.shape[0]))\n",
        "speed_up = []\n",
        "\n",
        "print(\"Computing error and speedup analysis\")\n",
        "\n",
        "for mu in testing_set:\n",
        "  \n",
        "  thetaA2 = mu[0]\n",
        "  thetaf1 = mu[1]\n",
        "\n",
        "  ##### full #####\n",
        "  thetaA1 = mu[0]\n",
        "  mu_2 = mu[1]\n",
        "  \n",
        "  #### the problem is not affine: I have to assemble in this stage!! ###\n",
        "  start_time_assemble = time.time()\n",
        "  J_f_1 = gedim.AssembleForcingTerm(Stokes_f_1, speed_problemData, lib)\n",
        "  J_f_2 = gedim.AssembleForcingTerm(Stokes_f_2, speed_problemData, lib)\n",
        "  J_f = np.concatenate([J_f_1, J_f_2, np.zeros(pressure_n_dofs)])\n",
        "  time_assemble = time.time() - start_time_assemble\n",
        "  lhs = thetaA1*(J_X_1 + J_X_2) - J_B_1 - J_B_2 - np.transpose(J_B_1) - np.transpose(J_B_2)\n",
        "  rhs = J_f\n",
        "  \n",
        "  start_fom = time.time()\n",
        "  full_solution = gedim.LUSolver(lhs, rhs, lib)\n",
        "  time_fom = time.time() - start_fom\n",
        "\n",
        "  full_solution_u = full_solution[0:2*speed_n_dofs]\n",
        "  full_solution_p = full_solution[2*speed_n_dofs:]\n",
        "\n",
        "  #### reduced #####\n",
        "\n",
        "  reduced_lhs = thetaA1*reduced_stiff_Stokes - reduced_divergence_operator_1 - reduced_divergence_operator_2 - np.transpose(reduced_divergence_operator_1) - np.transpose(reduced_divergence_operator_2)\n",
        "  reduced_rhs = assemble_reduced_vector(global_basis_function_matrix, J_f)\n",
        "  \n",
        "  start_rom = time.time()\n",
        "  reduced_solution = np.linalg.solve(reduced_lhs, reduced_rhs)\n",
        "  time_rom = time.time() - start_rom\n",
        "  \n",
        "  speed_up.append(time_fom/(time_rom+time_assemble))\n",
        "  \n",
        "  reduced_solution_FE_basis = global_basis_function_matrix @ reduced_solution\n",
        "  reduced_u_FE = reduced_solution_FE_basis[0:2*speed_n_dofs]\n",
        "  reduced_p_FE = reduced_solution_FE_basis[2*speed_n_dofs:]\n",
        "\n",
        "  ### computing error\n",
        "  \n",
        "  abs_err_u_mu = compute_error(full_solution_u, reduced_u_FE, inner_product=inner_product_u, type_err=\"absolute\")\n",
        "  rel_err_u_mu = compute_error(full_solution_u, reduced_u_FE, inner_product=inner_product_u)\n",
        "  abs_err_u.append(abs_err_u_mu)\n",
        "  rel_err_u.append(rel_err_u_mu)\n",
        "\n",
        "  abs_err_p_mu = compute_error(full_solution_p, reduced_p_FE, type_err=\"absolute\")\n",
        "  rel_err_p_mu = compute_error(full_solution_p, reduced_p_FE)\n",
        "  abs_err_p.append(abs_err_p_mu)\n",
        "  rel_err_p.append(rel_err_p_mu)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"avarege relative error for velocity = \", np.mean(rel_err_u) )\n",
        "print(\"avarege absolute error for velocity = \", np.mean(abs_err_u) )\n",
        "\n",
        "print(\"avarege relative error for pressure = \", np.mean(rel_err_p) )\n",
        "print(\"avarege absolute error for pressure = \", np.mean(abs_err_p) )\n",
        "\n",
        "\n",
        "print(\"avarege speed_up = \", np.mean(speed_up) )"
      ],
      "metadata": {
        "id": "kpFbExusAw4A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}