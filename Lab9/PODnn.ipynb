{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IGuNCbv2QpF"
      },
      "source": [
        "# **POD-NN**\n",
        "\n",
        "POD-NN is a strategy that allows not to rely on affinity on the online stage: the projection stage is not performed and thus the speedup is guaranteed, yes having accurate solutions.\n",
        "The POD-NN algorithm relies on two stages:\n",
        "1. a POD,\n",
        "2. a training of a Feed-forward Neural Network that predicts the entries of the reduced vector $u_{\\mathsf{rb}}$.\n",
        "\n",
        "As usual, we need **a lot of FOM simulations**. Let us import gedim!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOKm4Cpr0agg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/fvicini/CppToPython.git\n",
        "%cd CppToPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVlYTB8mifCl"
      },
      "outputs": [],
      "source": [
        "!git submodule init\n",
        "!git submodule update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xezfpm75i_FG"
      },
      "outputs": [],
      "source": [
        "!mkdir -p externals\n",
        "%cd externals\n",
        "!cmake -DINSTALL_VTK=OFF -DINSTALL_LAPACK=OFF ../gedim/3rd_party_libraries\n",
        "!make -j4\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LamP-IF1tLt"
      },
      "outputs": [],
      "source": [
        "!mkdir -p release\n",
        "%cd release \n",
        "!cmake -DCMAKE_PREFIX_PATH=\"/content/CppToPython/externals/Main_Install/eigen3;/content/CppToPython/externals/Main_Install/triangle;/content/CppToPython/externals/Main_Install/tetgen;/content/CppToPython/externals/Main_Install/googletest\" ../\n",
        "!make -j4 GeDiM4Py\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeaV-lky4gkR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import GeDiM4Py as gedim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13zM04WMQ5hJ"
      },
      "outputs": [],
      "source": [
        "lib = gedim.ImportLibrary(\"./release/GeDiM4Py.so\")\n",
        "\n",
        "config = { 'GeometricTolerance': 1.0e-8 }\n",
        "gedim.Initialize(config, lib)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubq1Ge_iQkak"
      },
      "source": [
        "## The parametric version of the heat conductivity equation\n",
        "\n",
        "Solving the following equation on square $\\bar{\\Omega} = [-1, +1] \\times [-1, +1]$\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "\\nabla \\cdot (k_{\\mu} \\nabla u) = 0 & \\text{in } \\Omega\\\\\n",
        "k_{\\mu} \\nabla u \\cdot n_1 = \\mu_2 & \\text{in } \\Gamma_{down}\\\\\n",
        "u = \\sin(\\mu_3\\pi x) & \\text{in } \\Gamma_{up}\\\\\n",
        "k_{\\mu} \\nabla u \\cdot n_2 = 0 & \\text{otherwise} \n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where $k = \\mu_1$ if $x^2 + y^2 \\leq R^2$ and $k = 1$ otherwise. \n",
        "The parametric space is $\\mathcal P = [0.1, 10] \\times [0,1] \\times [-1, 1]$.\n",
        "\n",
        "The problem is _standard_. However, we note a nonlinear dependency of the Dirichlet boundary term over $\\Gamma_{up}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOPeoKRlRNMo"
      },
      "outputs": [],
      "source": [
        "def Heat_R():\n",
        "\treturn 0.5\n",
        "\n",
        "def Domain(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = np.ones(numPoints)\n",
        "\treturn values.ctypes.data\n",
        "\n",
        "############## DIRICHLET VARYING WRT mu_3 #####################\n",
        "def Dirichlet_Term(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = np.ones(numPoints)\n",
        "\tfor p in range(0, numPoints):\n",
        "\t\tvalues[p] = np.sin(mu_3*np.pi*matPoints[0,p])  ### mu_3 is not defined, but not a problem\n",
        "\treturn values.ctypes.data\n",
        "###################\n",
        "\n",
        "def Circle(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = np.ones(numPoints)\n",
        "\tfor p in range(0, numPoints):\n",
        "\t\tif (matPoints[0,p] * matPoints[0,p] + matPoints[1,p] * matPoints[1,p]) > (Heat_R() * Heat_R() + 1.0e-16):\n",
        "\t\t\tvalues[p] = 0. \n",
        "\treturn values.ctypes.data\n",
        "\n",
        "def NotCircle(numPoints, points):\n",
        "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
        "\tvalues = np.ones(numPoints)\n",
        "\tfor p in range(0, numPoints):\n",
        "\t\tif (matPoints[0,p] * matPoints[0,p] + matPoints[1,p] * matPoints[1,p]) <= (Heat_R() * Heat_R() + 1.0e-16):\n",
        "\t\t\tvalues[p] = 0. \n",
        "\treturn values.ctypes.data\n",
        "\n",
        "def Heat_weakTerm_down(numPoints, points):\n",
        "\tvalues = np.ones(numPoints) \n",
        "\treturn values.ctypes.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9JEfUdDRH5W"
      },
      "source": [
        "Let us define the High Fidelity Simulation Parameters and import the mesh."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfzHSAXORH5X"
      },
      "outputs": [],
      "source": [
        "order = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZXNw6gDlHZt"
      },
      "outputs": [],
      "source": [
        "%%writefile ImportMesh.csv\n",
        "InputFolderPath\n",
        "./Meshes/Mesh3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFrwWHkGRTcM"
      },
      "outputs": [],
      "source": [
        "[meshInfo, mesh] = gedim.ImportDomainMesh2D(lib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FifaSs5tRWLp"
      },
      "outputs": [],
      "source": [
        "gedim.PlotMesh(mesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFLs55ZIRjRw"
      },
      "source": [
        "Let us create the space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtVL7IqnRlra"
      },
      "outputs": [],
      "source": [
        "discreteSpace = { 'Order': order, 'Type': 1, 'BoundaryConditionsType': [1, 3, 3, 2] }\n",
        "[problemData, dofs, strongs] = gedim.Discretize(discreteSpace, lib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNKv663YRvMJ"
      },
      "outputs": [],
      "source": [
        "gedim.PlotDofs(mesh, dofs, strongs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-GPibkUR0yD"
      },
      "source": [
        "### **Assemble the system**\n",
        "We can assemble only the parts that are $\\mu-$independent (together with the inner product matrix!). Namely, the Dirichlet term needs to be assembled later on. It is non-affine and nonlinear w.r.t to the parameter $\\boldsymbol\\mu$!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7XmYDOGR1m4"
      },
      "outputs": [],
      "source": [
        "\n",
        "[stiffness1, stiffnessStrong1] = gedim.AssembleStiffnessMatrix(NotCircle, problemData, lib)\n",
        "[stiffness2, stiffnessStrong2] = gedim.AssembleStiffnessMatrix(Circle, problemData, lib)\n",
        "\t\n",
        "weakTerm_down1 = gedim.AssembleWeakTerm(Heat_weakTerm_down, 1, problemData, lib)\n",
        "\n",
        "\n",
        "#### inner product  \n",
        "# ||grad(u)||^2 \n",
        "\n",
        "\n",
        "inner_product = stiffness1 + stiffness2\n",
        "\n",
        "######## DIRICHLET CANNOT BE ASSEMBLED NOW #########################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define the training set for the POD"
      ],
      "metadata": {
        "id": "-8-q7bvsJrPs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2dzS4-3dZm2"
      },
      "outputs": [],
      "source": [
        "### define the training set\n",
        "\n",
        "snapshot_num = 300\n",
        "mu1_range = [0.1, 10.]\n",
        "mu2_range = [-1., 1.]\n",
        "mu3_range = [-1., 1.]\n",
        "P = np.array([mu1_range, mu2_range, mu3_range])\n",
        "\n",
        "training_set = np.random.uniform(low=P[:, 0], high=P[:, 1], size=(snapshot_num, P.shape[0]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now proceed with the snapshot matrix creation. However, we need to be careful: the problem is not affine in the parameters and we need to assemble the Dirichlet term for each parametric instance."
      ],
      "metadata": {
        "id": "eAx-TCClKO0f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJDt8TvQdW8Z"
      },
      "outputs": [],
      "source": [
        "#### snapshot matrix creation\n",
        "thetaA1 = 1\n",
        "snapshot_matrix = []\n",
        "\n",
        "tol = 1. - 1e-7\n",
        "N_max = 10\n",
        "\n",
        "for mu in training_set:\n",
        "  thetaA2 = mu[0]\n",
        "  thetaf1 = mu[1]\n",
        "  mu_3 = mu[2]\n",
        "  \n",
        "  #### the problem is not affine: I have to assemble in this stage!! ###\n",
        "  Dirichlet_top = gedim.AssembleStrongSolution(Dirichlet_Term, 3, problemData, lib) ## label \n",
        "  f1_D = stiffnessStrong1 @ Dirichlet_top\n",
        "  f2_D = stiffnessStrong2 @ Dirichlet_top\n",
        "\n",
        "  stiffness = thetaA1*stiffness1 + thetaA2*stiffness2\n",
        "  weakTerm_down = thetaf1*weakTerm_down1\n",
        "  Dirichlet_contribution = thetaA1*f1_D + thetaA2*f2_D\n",
        "  \n",
        "  f = weakTerm_down - Dirichlet_contribution\n",
        "  \n",
        "  snapshot = gedim.LUSolver(stiffness, f, lib)\n",
        "  \n",
        "  # if you do not want to plot uncomment\n",
        "  # gedim.PlotSolution(mesh, dofs, strongs, snapshot, Dirichlet_top)\n",
        "  \n",
        "  \n",
        "  snapshot_matrix.append(np.copy(snapshot))\n",
        "\n",
        "snapshot_matrix = np.array(snapshot_matrix) \n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us build and analyze the covariance matrix."
      ],
      "metadata": {
        "id": "nRDG_PFyMSq4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VxLRw6TgNM9"
      },
      "outputs": [],
      "source": [
        "### covariance matrix\n",
        "\n",
        "C = snapshot_matrix @ inner_product @ np.transpose(snapshot_matrix) ## metti inner product\n",
        "\n",
        "# VM, L, VMt = np.linalg.svd((C))\n",
        "\n",
        "L_e, VM_e = np.linalg.eig(C)\n",
        "eigenvalues = []\n",
        "eigenvectors = []\n",
        "\n",
        "\n",
        "#### check\n",
        "\n",
        "for i in range(len(L_e)):\n",
        "  eig_real = L_e[i].real\n",
        "  eig_complex = L_e[i].imag\n",
        "  assert np.isclose(eig_complex, 0.)\n",
        "  eigenvalues.append(eig_real)\n",
        "  eigenvectors.append(VM_e[i].real)\n",
        "\n",
        "\n",
        "total_energy = sum(eigenvalues)\n",
        "retained_energy_vector = np.cumsum(eigenvalues)\n",
        "relative_retained_energy = retained_energy_vector/total_energy\n",
        "\n",
        "\n",
        "if all(flag==False for flag in relative_retained_energy>= tol):\n",
        "  N = N_max\n",
        "else:\n",
        "  N = np.argmax(relative_retained_energy >= tol) + 1\n",
        "\n",
        "print(N)\n",
        "print(relative_retained_energy)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let us build the basis functions and $\\mathbb B$."
      ],
      "metadata": {
        "id": "Zb8ujbsKMyw_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jwa2PNh57RW7"
      },
      "outputs": [],
      "source": [
        "# Create the basis function matrix\n",
        "basis_functions = []\n",
        "for n in range(N):\n",
        "  eigenvector =  eigenvectors[n]\n",
        "  basis = np.transpose(snapshot_matrix)@eigenvector\n",
        "  norm = np.sqrt(np.transpose(basis) @ inner_product @ basis) ## metti inner product\n",
        "  basis /= norm\n",
        "  basis_functions.append(np.copy(basis))\n",
        "\n",
        "basis_functions = np.transpose(np.array(basis_functions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to perform standard ROMs we still need to assemble the system.\n",
        "\n",
        "**Can we asseble it?**"
      ],
      "metadata": {
        "id": "5QdveiY7Nihh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOYumQbDGCLA"
      },
      "outputs": [],
      "source": [
        "########## ASSEMBLE WHAT I CAN ##### STILL OFFLINE\n",
        "reduced_stiff1 = np.transpose(basis_functions) @ stiffness1 @ basis_functions\n",
        "reduced_stiff2 = np.transpose(basis_functions) @ stiffness2 @ basis_functions\n",
        "reduced_w =  np.transpose(basis_functions) @ weakTerm_down1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each new parameter I have to assemble the Dirichlet term, once again."
      ],
      "metadata": {
        "id": "TWdxpcmpN_Aa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2ziPtyYqthv"
      },
      "outputs": [],
      "source": [
        "########### I CANNOT DO THAT ################ STILL ONLINE??? WE NEED THE PARAMETER\n",
        "thetaA2 = 2.\n",
        "thetaf1 = 0.8\n",
        "mu_3 = 1.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV91kHlbrZ6R"
      },
      "outputs": [],
      "source": [
        "#### the problem is not affine: I have to assemble in this stage!! ###\n",
        "\n",
        "Dirichlet_top = gedim.AssembleStrongSolution(Dirichlet_Term, 3, problemData, lib) ## label \n",
        "f1_D = stiffnessStrong1 @ Dirichlet_top\n",
        "f2_D = stiffnessStrong2 @ Dirichlet_top\n",
        "r_f1_D = np.transpose(basis_functions) @ (stiffnessStrong1 @ Dirichlet_top)\n",
        "r_f2_D = np.transpose(basis_functions) @ (stiffnessStrong2 @ Dirichlet_top)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcVTiQGqR-oz"
      },
      "source": [
        "**Solve linear system for a new $\\mu$**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfINEnRbR_31"
      },
      "outputs": [],
      "source": [
        "reduced_rhs = thetaA1*reduced_stiff1 + thetaA2*reduced_stiff2\n",
        "reduced_lhs = thetaf1*reduced_w - (thetaA1*r_f1_D + thetaA2*r_f2_D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVY6EPrPSU5G"
      },
      "outputs": [],
      "source": [
        "#####solve \n",
        "\n",
        "reduced_solution = np.linalg.solve(reduced_rhs, reduced_lhs)\n",
        "print(reduced_solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdIlITaWSkRW"
      },
      "outputs": [],
      "source": [
        "###### plot #######àà\n",
        "proj_reduced_solution = basis_functions @ reduced_solution\n",
        "gedim.PlotSolution(mesh, dofs, strongs, proj_reduced_solution, Dirichlet_top)\n",
        "\n",
        "stiffness = thetaA1*stiffness1 + thetaA2*stiffness2\n",
        "weakTerm_down = thetaf1*weakTerm_down1\n",
        "f = weakTerm_down - (thetaA1*stiffnessStrong1 + thetaA2*stiffnessStrong2) @ Dirichlet_top\n",
        "  \n",
        "full_solution = gedim.LUSolver(stiffness, f, lib)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6Qajo4RSDLC"
      },
      "outputs": [],
      "source": [
        "gedim.PlotSolution(mesh, dofs, strongs, full_solution, Dirichlet_top)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us comment a bit on the error analysis and the _speed up_."
      ],
      "metadata": {
        "id": "H7OJM-LqPgrn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G19gtthVsw9l"
      },
      "outputs": [],
      "source": [
        "### compute error\n",
        "import time\n",
        "\n",
        "abs_err = []\n",
        "rel_err = []\n",
        "testing_set = np.random.uniform(low=P[:, 0], high=P[:, 1], size=(100, P.shape[0]))\n",
        "speed_up = []\n",
        "\n",
        "print(\"Computing error and speedup analysis\")\n",
        "\n",
        "for mu in testing_set:\n",
        "  \n",
        "  thetaA2 = mu[0]\n",
        "  thetaf1 = mu[1]\n",
        "  mu_3 = mu[2]\n",
        "  \n",
        "  #### the problem is not affine: I have to assemble in this stage!! ###\n",
        "  start_assembling = time.time()\n",
        "  Dirichlet_top = gedim.AssembleStrongSolution(Dirichlet_Term, 3, problemData, lib) ## label \n",
        "  f1_D = stiffnessStrong1 @ Dirichlet_top\n",
        "  f2_D = stiffnessStrong2 @ Dirichlet_top\n",
        "  r_f1_D = np.transpose(basis_functions) @ (stiffnessStrong1 @ Dirichlet_top)\n",
        "  r_f2_D = np.transpose(basis_functions) @ (stiffnessStrong2 @ Dirichlet_top)\n",
        "  time_assembling =  time.time() - start_assembling\n",
        "\n",
        "  ##### full #####\n",
        "  stiffness = thetaA1*stiffness1 + thetaA2*stiffness2\n",
        "  weakTerm_down = thetaf1*weakTerm_down1\n",
        "  f = weakTerm_down - (thetaA1*stiffnessStrong1 + thetaA2*stiffnessStrong2) @ Dirichlet_top\n",
        "  \n",
        "  \n",
        "  start_fom = time.time()\n",
        "  full_solution = gedim.LUSolver(stiffness, f, lib)\n",
        "  time_fom = time.time() - start_fom\n",
        "\n",
        "  #### reduced #####\n",
        "\n",
        "  reduced_rhs = thetaA1*reduced_stiff1 + thetaA2*reduced_stiff2\n",
        "  reduced_lhs = thetaf1*reduced_w - (thetaA1*r_f1_D + thetaA2*r_f2_D)\n",
        "  \n",
        "  start_rom = time.time()\n",
        "  reduced_solution = np.linalg.solve(reduced_rhs, reduced_lhs)\n",
        "  time_rom = time.time() - start_rom\n",
        "  \n",
        "  speed_up.append(time_fom/(time_rom + time_assembling))\n",
        "  \n",
        "  proj_reduced_solution = basis_functions@reduced_solution\n",
        "\n",
        "  ### computing error\n",
        "\n",
        "  error_function = full_solution - proj_reduced_solution\n",
        "  error_norm_squared_component = np.transpose(error_function) @ inner_product @ error_function\n",
        "  absolute_error = np.sqrt(abs(error_norm_squared_component))\n",
        "  abs_err.append(absolute_error)\n",
        "  \n",
        "  full_solution_norm_squared_component = np.transpose(full_solution) @  inner_product @ full_solution\n",
        "  relative_error = absolute_error/np.sqrt(abs(full_solution_norm_squared_component))\n",
        "  rel_err.append(relative_error)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxQFFzPdt7nE"
      },
      "outputs": [],
      "source": [
        "print(\"avarege relative error = \", np.mean(rel_err) )\n",
        "print(\"avarege absolute error = \", np.mean(abs_err) )\n",
        "print(\"avarege speed_up = \", np.mean(speed_up) )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The speed up is quite small for a linear problem. Let understand the role of POD-NN in this setting. \n",
        "\n",
        "We want to use a feed-forward NN. Let us define the Class Net with pytorch."
      ],
      "metadata": {
        "id": "Mvmq5XX2RXgw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3BFhlmXvxFe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "mu_dim = P.shape[0]\n",
        "basis_dim = N \n",
        "input_dim = mu_dim\n",
        "output_dim = basis_dim\n",
        "nodes = 30\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, nodes) \n",
        "        self.fc2 = nn.Linear(nodes, nodes)\n",
        "        self.fc3 = nn.Linear(nodes, nodes)\n",
        "        self.fc4 = nn.Linear(nodes, nodes)\n",
        "        self.fc5 = nn.Linear(nodes, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "        # self.apply(self._init_weights)\n",
        "\n",
        "\n",
        "    def forward(self, x):  ### Forward law ----> prediction\n",
        "        x = self.tanh(self.fc1(x))   \n",
        "        x = self.tanh(self.fc2(x))\n",
        "        x = self.tanh(self.fc3(x))\n",
        "        x = self.tanh(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pROPwZjT-1VB"
      },
      "outputs": [],
      "source": [
        "seed_num = 31\n",
        "torch.manual_seed(seed_num)\n",
        "net = Net()\n",
        "torch.set_default_dtype(torch.float32)\n",
        "\n",
        "my_loss = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "epoch_max = 500000\n",
        "epoch = 0\n",
        "tol = 1e-5\n",
        "loss = 1."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to prepare the outputs to train the NN. Indeed, our goal is to define \n",
        "$$\n",
        "\\boldsymbol \\pi(\\boldsymbol \\mu) = \\underline{u}_{\\mathsf{rb}}^{NN}(\\boldsymbol \\mu).\n",
        "$$\n",
        " Namely, our inputs are the parameters of the training set and the output is the Galerkin projection of the snapshots of the training set.\n",
        " The output is of the form $\\underline{u}_{\\mathsf{rb}}$ where:\n",
        " $$\n",
        " \\mathbb B \\underline{u}_{\\mathsf{rb}}(\\boldsymbol \\mu) = \\mathbb P^{\\boldsymbol \\mu}u_{{\\delta}}(\\boldsymbol \\mu), \\quad \\quad (1)\n",
        " $$\n",
        " where $\\mathbb P^{\\boldsymbol \\mu} = \\mathbb B \\mathbb X_{N}^{-1} \\mathbb B^T\\mathbb X_{N_{\\delta}}$ is the reduced vector related to the Galrkin projector, i.e. the best approximation of $u_\\delta$ in $V_N$ w.r.t. the inner-product defined by the matrix $X_\\delta$.\n",
        "\n",
        " Instead of computing the inverse of $\\mathbb X_{N} = \\mathbb B^T \\mathbb X_{{\\delta}} \\mathbb B$ we solve the following system:\n",
        " $$\n",
        " \\mathbb B^T \\mathbb X_{{\\delta}} \\mathbb B \\underline{u}_{\\mathsf {rb}}(\\boldsymbol \\mu) =\n",
        " \\mathbb X_{N} \\mathbb B \\underline{u}_{\\mathsf {rb}}(\\boldsymbol \\mu)\n",
        "  \\mathbb B^T \\mathbb X_{{\\delta}} u_{{\\delta}}(\\boldsymbol \\mu)\n",
        " $$\n",
        " to find $u_{\\mathsf{rb}}(\\boldsymbol \\mu)$ for each snapshot.\n",
        "\n",
        "In this way we are taking the vector of the reduced solution related to the parameter $\\boldsymbol \\mu$ **without solving the reduced system**, thanks to the relation (1). This element is the closest element (the best choice) to $u_{\\delta}$ in the norm of the problem."
      ],
      "metadata": {
        "id": "TVd-BHZbX65A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzKJT4eSBSIW"
      },
      "outputs": [],
      "source": [
        "####### training set ########\n",
        "reduced_inner_product = np.transpose(basis_functions) @ inner_product @ basis_functions\n",
        "x_train = torch.tensor(np.float32(training_set))\n",
        "y_train = []\n",
        "\n",
        "\n",
        "for i in range(snapshot_matrix.shape[0]):\n",
        "  \n",
        "  snapshot_to_project = snapshot_matrix[i]\n",
        "  \n",
        "  projected_snapshot = np.linalg.solve(reduced_inner_product, np.transpose(basis_functions)@inner_product@snapshot_to_project)\n",
        "  \n",
        "  y_train.append(projected_snapshot)\n",
        "\n",
        "y_train = np.float32(y_train)\n",
        "y_train = torch.tensor(y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us train our neural network!"
      ],
      "metadata": {
        "id": "5WsoksHBejAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba7lzX3NAG5R"
      },
      "outputs": [],
      "source": [
        "while loss >= tol and epoch < epoch_max:\n",
        "  epoch = epoch + 1\n",
        "  optimizer.zero_grad()\n",
        "          \n",
        "  ## compute output\n",
        "  output = net(x_train)\n",
        "  \n",
        "          \n",
        "  loss = my_loss(output, y_train)\n",
        "  if epoch >= 20000:\n",
        "    optimizer.param_groups[0]['lr'] = 0.0001  \n",
        "  #compute the gradients\n",
        "  loss.backward()\n",
        "  # optimizer update\n",
        "  optimizer.step()\n",
        "  if epoch % 200 == 199:\n",
        "    print(\"epoch\", epoch, 'loss', loss.item(), 'lr', optimizer.param_groups[0]['lr'] )\n",
        "              "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us compute a specific instance of the problem! Namely we compute $\\boldsymbol \\pi (\\boldsymbol \\mu_{test})$.\n",
        "\n",
        "**What is the output?**\n",
        "\n",
        "Let us compare it with the full solution.\n",
        "\n",
        "**What do I have to do?**"
      ],
      "metadata": {
        "id": "0hGZHCs-eo40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjth0m2sLh7h"
      },
      "outputs": [],
      "source": [
        "x_test = [[6., .1, 1.]]\n",
        "x_test = np.float32(x_test)\n",
        "x_test = torch.tensor(x_test)\n",
        "\n",
        "reduced_solution = np.asarray(net(x_test).detach().numpy())[0]\n",
        "\n",
        "print(reduced_solution)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaiTio9rMJL4"
      },
      "outputs": [],
      "source": [
        "nn_proj_reduced_solution = basis_functions @ reduced_solution\n",
        "mu = x_test[0]\n",
        "thetaA2 = mu[0].item()\n",
        "thetaf1 = mu[1].item()\n",
        "mu_3 = mu[2].item()\n",
        "thetaA1 = 1\n",
        "Dirichlet_top = gedim.AssembleStrongSolution(Dirichlet_Term, 3, problemData, lib)\n",
        " \n",
        "\n",
        "gedim.PlotSolution(mesh, dofs, strongs, nn_proj_reduced_solution, Dirichlet_top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_2bDOggXOSm"
      },
      "outputs": [],
      "source": [
        "##### full #####\n",
        "\n",
        "stiffness = thetaA1*stiffness1 + thetaA2*stiffness2\n",
        "weakTerm_down = thetaf1*weakTerm_down1\n",
        "f = weakTerm_down - (thetaA1*stiffnessStrong1 + thetaA2*stiffnessStrong2) @ Dirichlet_top\n",
        "full_solution = gedim.LUSolver(stiffness, f, lib)\n",
        "  \n",
        "\n",
        "full_solution = gedim.LUSolver(stiffness, f, lib)\n",
        "gedim.PlotSolution(mesh, dofs, strongs, full_solution, Dirichlet_top)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us perform an error analysis and comment on the speed up!"
      ],
      "metadata": {
        "id": "2oBdwVeegDNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### compute error\n",
        "import time\n",
        "\n",
        "abs_err = []\n",
        "rel_err = []\n",
        "testing_set = np.random.uniform(low=P[:, 0], high=P[:, 1], size=(100, P.shape[0]))\n",
        "speed_up = []\n",
        "\n",
        "print(\"Computing error and speedup analysis\")\n",
        "\n",
        "for mu in testing_set:\n",
        "  \n",
        "  thetaA2 = mu[0]\n",
        "  thetaf1 = mu[1]\n",
        "  mu_3 = mu[2]\n",
        "  \n",
        "  #### I DO NOT NEED THE SOLVE #####\n",
        "  Dirichlet_top = gedim.AssembleStrongSolution(Dirichlet_Term, 3, problemData, lib) ## label \n",
        "  \n",
        "  ##### full #####\n",
        "  stiffness = thetaA1*stiffness1 + thetaA2*stiffness2\n",
        "  weakTerm_down = thetaf1*weakTerm_down1\n",
        "  f = weakTerm_down - (thetaA1*stiffnessStrong1 + thetaA2*stiffnessStrong2) @ Dirichlet_top\n",
        "  \n",
        "  \n",
        "  start_fom = time.time()\n",
        "  full_solution = gedim.LUSolver(stiffness, f, lib)\n",
        "  time_fom = time.time() - start_fom\n",
        "  # gedim.PlotSolution(mesh, dofs, strongs, full_solution, Dirichlet_top)\n",
        "  #### reduced #####\n",
        "\n",
        "  x_test = [[mu[0], mu[1], mu[2]]]\n",
        "  x_test = np.float32(x_test)\n",
        "  x_test = torch.tensor(x_test)\n",
        "\n",
        "  start_rom = time.time()\n",
        "  reduced_solution = np.asarray(net(x_test).detach().numpy())[0]\n",
        "  time_rom = time.time() - start_rom\n",
        "  \n",
        "  speed_up.append(time_fom/(time_rom))\n",
        "  \n",
        "  proj_reduced_solution = basis_functions@reduced_solution\n",
        "  # gedim.PlotSolution(mesh, dofs, strongs, proj_reduced_solution, Dirichlet_top)\n",
        "\n",
        "  \n",
        "  ### computing error\n",
        "\n",
        "  error_function = full_solution - proj_reduced_solution\n",
        "  error_norm_squared_component = np.transpose(error_function) @ inner_product @ error_function\n",
        "  absolute_error = np.sqrt(abs(error_norm_squared_component))\n",
        "  print(absolute_error)\n",
        "  abs_err.append(absolute_error)\n",
        "  \n",
        "  full_solution_norm_squared_component = np.transpose(full_solution) @  inner_product @ full_solution\n",
        "  relative_error = absolute_error/np.sqrt(abs(full_solution_norm_squared_component))\n",
        "  rel_err.append(relative_error)\n",
        "  print(relative_error)\n",
        "  \n"
      ],
      "metadata": {
        "id": "O74xZD77-5QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"avarege relative error = \", np.mean(rel_err) )\n",
        "print(\"avarege absolute error = \", np.mean(abs_err) )\n",
        "print(\"avarege speed_up = \", np.mean(speed_up) )"
      ],
      "metadata": {
        "id": "PolChbcfAxgk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}